[{"content":"引言\r人工智能（AI）技术的迅猛发展推动了各行各业的数字化转型。图像分类，作为计算机视觉领域的核心技术之一，能够让机器自动识别图像中的物体、场景或特征，已广泛应用于医疗诊断、安防监控、自动驾驶和电子商务等领域。\n与此同时，.NET 平台凭借其高效性、跨平台能力和强大的 C# 编程语言支持，成为开发者构建企业级应用的首选技术栈。将 AI 图像分类模型与 .NET 技术结合，不仅能充分发挥两者的优势，还能为开发者提供一种高效、直观的实现方式。\n本文将详细介绍如何在 .NET 环境下使用 C# 部署和调用 AI 图像分类模型。我们将从环境搭建、模型选择，到模型调用，再到实际应用场景，逐步展开讲解，并提供丰富的代码示例和实践指导，帮助开发者快速上手并应用到实际项目中。\n准备工作\r在开始实现图像分类之前，我们需要准备必要的开发环境和工具。以下是所需的软件和库：\nVisual Studio：Visual Studio 2022。 .NET SDK：安装 .NET 6.0 或更高版本，确保支持最新的功能和性能优化。 ML.NET：微软提供的开源机器学习框架，专为 .NET 开发者设计，支持模型训练和推理。 模型文件：我们将使用预训练的图像分类模型 tensorflow_inception_graph.pb。 安装步骤\r创建项目并添加依赖：在命令行中运行以下命令，创建一个控制台应用程序并安装必要的 NuGet 包：\n1 dotnet new console -n ImageClassificationDemocd ImageClassificationDemodotnet add package Microsoft.MLdotnet add package Microsoft.ML.ImageAnalyticsdotnet add package Microsoft.ML.TensorFlowdotnet add package SciSharp.TensorFlow.Redist 完成以上步骤后，你的环境就准备好了。接下来，我们将选择一个合适的图像分类模型。\n图像分类模型的选择\r图像分类模型是基于监督学习的神经网络，其目标是将输入图像分配到预定义的类别中。在选择模型时，我们需要考虑模型的性能、计算复杂度和适用场景。以下是几种常见的图像分类模型：\n卷积神经网络（CNN）：如 LeNet、AlexNet 和 VGGNet，适合基本的图像分类任务，但层数较深时可能面临梯度消失问题。 残差网络（ResNet）：通过引入残差连接（skip connections），解决了深层网络的训练难题，适用于高精度分类任务。 EfficientNet：通过平衡网络深度、宽度和分辨率，提供高效的性能，适合资源受限的场景。 模型训练与导出\r考虑到时间和资源成本，我们将直接使用预训练的 tensorflow_inception_graph.pb 模型。如果你有自定义需求，可以使用以下步骤训练并导出模型：\n数据准备：收集并标注图像数据集，分为训练集和验证集。 训练模型：使用 TensorFlow 或 PyTorch 等框架训练模型。 导出模型：利用框架提供的导出工具导出模型。 在本文中，我们选择 tensorflow_inception_graph.pb 作为示例模型，这是一种由Google开发的高性能卷积神经网络（CNN）架构。\n❝\n该模块通过并行使用不同大小的卷积核（如1x1、3x3、5x5）和池化层，提取图像的多尺度特征。这种设计提高了模型在图像分类任务中的表现，同时保持了计算效率。支持 1000 个类别的分类，且可以轻松集成到 .NET 中。\n大家可以直接点击 tensorflow_inception_graph.pb 下载（文章最后也有下载方式）预训练的模型文件和分类文件，并将其放入项目目录中。\n也可以到github上下载（文章最后也有下载方式），里面的内容相对来说也更丰富些。\n在 .NET 中调用模型\r现在，我们进入核心部分：在 .NET 中调用 tensorflow_inception_graph.pb。以下是逐步实现的过程。\n1. 创建 .NET 项目\r使用命令行创建一个控制台应用，项目基本结构如下：\n1 ImageClassificationDemo/├── ImageClassificationDemo.csproj├── Program.cs├── assets/inputs/inception/tensorflow_inception_graph.pb├── assets/inputs/inception/imagenet_comp_graph_label_strings.txt 2. 定义输入和输出数据结构\r如果在运行的时候报错说找不到模型或者label文件，可以进行如下操作：\n输入类中定义数据的结构如下，后续会使用 TextLoader 加载数据时引用该类型。此处的类名为 ImageNetData：\n1 public class ImageNetData { [LoadColumn(0)] public string ImagePath; [LoadColumn(1)] public string Label; public static IEnumerable\u0026lt;ImageNetData\u0026gt; ReadFromCsv(string file, string folder) { return File.ReadAllLines(file) .Select(x =\u0026gt; x.Split(\u0026#39;\\t\u0026#39;)) .Select(x =\u0026gt; new ImageNetData { ImagePath = Path.Combine(folder, x[0]), Label = x[1] } ); } } public class ImageNetDataProbability : ImageNetData { public string PredictedLabel; public float Probability { get; set; } } ❝\n需要强调的是，ImageNetData 类中的标签在使用 TensorFlow 模型进行评分时并没有真正使用。而是在测试预测时使用它，这样就可以将每个样本数据的实际标签与 TensorFlow 模型提供的预测标签进行比较。\n输出类的结构如下：\n1 public class ImageNetPrediction{ [ColumnName(TFModelScorer.InceptionSettings.outputTensorName)] public float[] PredictedLabels;} Inception 模型还需要几个传入的默认参数：\n1 public struct ImageNetSettings{ public const int imageHeight = 224; public const int imageWidth = 224; public const float mean = 117; public const bool channelsLast = true;} 3. 定义 estimator 管道\r❝\n在处理深度神经网络时，必须使图像适应网络期望的格式。这就是图像被调整大小然后转换的原因（主要是像素值在所有R，G，B通道上被归一化）。\n1 var pipeline = mlContext.Transforms.LoadImages(outputColumnName: \u0026#34;input\u0026#34;, imageFolder: imagesFolder, inputColumnName: nameof(ImageNetData.ImagePath)) .Append(mlContext.Transforms.ResizeImages(outputColumnName: \u0026#34;input\u0026#34;, imageWidth: ImageNetSettings.imageWidth, imageHeight: ImageNetSettings.imageHeight, inputColumnName: \u0026#34;input\u0026#34;)) .Append(mlContext.Transforms.ExtractPixels(outputColumnName: \u0026#34;input\u0026#34;, interleavePixelColors: ImageNetSettings.channelsLast, offsetImage: ImageNetSettings.mean)) .Append(mlContext.Model.LoadTensorFlowModel(modelLocation) .ScoreTensorFlowModel(outputColumnNames: new[] { \u0026#34;softmax2\u0026#34; }, inputColumnNames: new[] { \u0026#34;input\u0026#34; }, addBatchDimensionInput:true)); 运行代码后，模型将被成功加载到内存中，接下来我们可以调用它进行图像分类。\n❝\n通常情况下，这里经常报的错就是输入/输出节点的名称不正确，你可以通过 Netron (https://netron.app/)工具查看输入/输出节点的名称。\n因为这两个节点的名称后面会在 estimator 的定义中使用：在 inception 网络的情况下，输入张量命名为 \u0026lsquo;input\u0026rsquo;，输出命名为 \u0026lsquo;softmax2\u0026rsquo;。\n下图是通过 Netron 读取的 tensorflow_inception_graph.pb 模型分析图：\n输入张量名 输出张量名\n4. 提取预测结果\r填充 estimator 管道\n1 ITransformer model = pipeline.Fit(data);var predictionEngine = mlContext.Model.CreatePredictionEngine\u0026lt;ImageNetData, ImageNetPrediction\u0026gt;(model); 当获得预测结果后，我们会在属性中得到一个浮点数数组。数组中的每个位置都会分配到一个标签。\n例如，如果模型有5个不同的标签，则数组将为length = 5。数组中的每个位置都表示标签在该位置的概率；所有数组值（概率）的和等于1。\n然后，您需要选择最大的值（概率），并检查配给了该位置的那个以填充 estimator 管道标签。\n调用模型进行图像分类\r接下来我们需要编写代码来加载图像、进行预测并解析结果。\n1. 准备素材与分类文件\r定义图像文件夹目录和图像分类目录。以下代码加载并预处理图像：\n1 string assetsRelativePath = @\u0026#34;../../../assets\u0026#34;;string assetsPath = GetAbsolutePath(assetsRelativePath);string tagsTsv = Path.Combine(assetsPath, \u0026#34;inputs\u0026#34;, \u0026#34;images\u0026#34;, \u0026#34;tags.tsv\u0026#34;);string imagesFolder = Path.Combine(assetsPath, \u0026#34;inputs\u0026#34;, \u0026#34;images\u0026#34;);string inceptionPb = Path.Combine(assetsPath, \u0026#34;inputs\u0026#34;, \u0026#34;inception\u0026#34;, \u0026#34;tensorflow_inception_graph.pb\u0026#34;);string labelsTxt = Path.Combine(assetsPath, \u0026#34;inputs\u0026#34;, \u0026#34;inception\u0026#34;, \u0026#34;imagenet_comp_graph_label_strings.txt\u0026#34;); 2. 加载模型\r1 private PredictionEngine\u0026lt;ImageNetData, ImageNetPrediction\u0026gt; LoadModel(string dataLocation, string imagesFolder, string modelLocation){ ConsoleWriteHeader(\u0026#34;Read model\u0026#34;); Console.WriteLine($\u0026#34;Model location: {modelLocation}\u0026#34;); Console.WriteLine($\u0026#34;Images folder: {imagesFolder}\u0026#34;); Console.WriteLine($\u0026#34;Training file: {dataLocation}\u0026#34;); Console.WriteLine($\u0026#34;Default parameters: image size=({ImageNetSettings.imageWidth},{ImageNetSettings.imageHeight}), image mean: {ImageNetSettings.mean}\u0026#34;); var data = mlContext.Data.LoadFromTextFile\u0026lt;ImageNetData\u0026gt;(dataLocation, hasHeader: true); var pipeline = mlContext.Transforms.LoadImages(outputColumnName: \u0026#34;input\u0026#34;, imageFolder: imagesFolder, inputColumnName: nameof(ImageNetData.ImagePath)) .Append(mlContext.Transforms.ResizeImages(outputColumnName: \u0026#34;input\u0026#34;, imageWidth: ImageNetSettings.imageWidth, imageHeight: ImageNetSettings.imageHeight, inputColumnName: \u0026#34;input\u0026#34;)) .Append(mlContext.Transforms.ExtractPixels(outputColumnName: \u0026#34;input\u0026#34;, interleavePixelColors: ImageNetSettings.channelsLast, offsetImage: ImageNetSettings.mean)) .Append(mlContext.Model.LoadTensorFlowModel(modelLocation). ScoreTensorFlowModel(outputColumnNames: new[] { \u0026#34;softmax2\u0026#34; }, inputColumnNames: new[] { \u0026#34;input\u0026#34; }, addBatchDimensionInput:true)); ITransformer model = pipeline.Fit(data); var predictionEngine = mlContext.Model.CreatePredictionEngine\u0026lt;ImageNetData, ImageNetPrediction\u0026gt;(model); return predictionEngine;} 3. 解析输出结果\r1 protected IEnumerable\u0026lt;ImageNetData\u0026gt; PredictDataUsingModel(string testLocation, string imagesFolder, string labelsLocation, PredictionEngine\u0026lt;ImageNetData, ImageNetPrediction\u0026gt; model){ ConsoleWriteHeader(\u0026#34;Classify images\u0026#34;); Console.WriteLine($\u0026#34;Images folder: {imagesFolder}\u0026#34;); Console.WriteLine($\u0026#34;Training file: {testLocation}\u0026#34;); Console.WriteLine($\u0026#34;Labels file: {labelsLocation}\u0026#34;); var labels = ReadLabels(labelsLocation); var testData = ImageNetData.ReadFromCsv(testLocation, imagesFolder); foreach (var sample in testData) { var probs = model.Predict(sample).PredictedLabels; var imageData = new ImageNetDataProbability() { ImagePath = sample.ImagePath, Label = sample.Label }; (imageData.PredictedLabel, imageData.Probability) = GetBestLabel(labels, probs); imageData.ConsoleWrite(); yield return imageData; }} 在 Main 方法中调用，完整代码如下：\n1 static void Main(string[] args){ string assetsRelativePath = @\u0026#34;../../../assets\u0026#34;; string assetsPath = GetAbsolutePath(assetsRelativePath); string tagsTsv = Path.Combine(assetsPath, \u0026#34;inputs\u0026#34;, \u0026#34;images\u0026#34;, \u0026#34;tags.tsv\u0026#34;); string imagesFolder = Path.Combine(assetsPath, \u0026#34;inputs\u0026#34;, \u0026#34;images\u0026#34;); string inceptionPb = Path.Combine(assetsPath, \u0026#34;inputs\u0026#34;, \u0026#34;inception\u0026#34;, \u0026#34;tensorflow_inception_graph.pb\u0026#34;); string labelsTxt = Path.Combine(assetsPath, \u0026#34;inputs\u0026#34;, \u0026#34;inception\u0026#34;, \u0026#34;imagenet_comp_graph_label_strings.txt\u0026#34;); try { TFModelScorer modelScorer = new TFModelScorer(tagsTsv, imagesFolder, inceptionPb, labelsTxt); modelScorer.Score(); } catch (Exception ex) { ConsoleHelpers.ConsoleWriteException(ex.ToString()); } ConsoleHelpers.ConsolePressAnyKey();} 运行程序后，你将看到类似以下的输出：\n其他实现方式\r在实际应用中，我们也可以使用ONNX模型，此处不做额外叙述。由于模型的性能和效率至关重要，只是提供一些优化建议：\n模型量化：使用 ONNX Runtime 的量化工具，将模型从浮点数（FP32）转换为整数（INT8），减少模型大小和推理时间。 硬件加速：结合 ONNX Runtime 的 GPU 支持，利用 CUDA 或 DirectML 加速推理。 批处理：如果需要处理多张图像，可以将输入组织为批次（batch），提高吞吐量。例如： 1 var inputs = new List\u0026lt;ImageInput\u0026gt; { input1, input2, input3 };var batchPrediction = mlContext.Data.LoadFromEnumerable(inputs);var predictions = model.Transform(batchPrediction); 缓存机制：对于频繁使用的模型，保持预测引擎的单例实例，避免重复加载。 通过这些优化，模型可以在 .NET 环境中实现更高的性能，满足实时应用的需求。\n实际应用场景\r图像分类模型在 .NET 应用中有广泛的用途，以下是几个典型场景：\n医疗影像分析 在医疗系统中，部署图像分类模型可以辅助医生识别 X 光片或 MRI 图像中的异常。例如，检测肺部结节或肿瘤。 2. 智能安防\n在监控系统中，模型可以实时识别可疑物体或行为，如检测闯入者或遗留物品。 3. 电子商务\n在商品管理系统中，自动分类上传的商品图像，提升搜索和推荐的准确性。\n挑战与解决方案\r数据隐私：通过加密传输和本地推理保护用户数据。 模型更新：定期从云端下载新模型，并使用版本控制管理。 计算资源：在资源受限的设备上，使用轻量化模型（如 MobileNet）。 结论\r本文详细介绍了如何在 .NET 环境下使用 C# 部署和调用 AI 图像分类模型。从环境搭建到模型选择、部署与调用，再到性能优化和应用场景，我们提供了一套完整的实践指南。通过 ML.NET 和预测模式的支持，开发者可以轻松地将强大的 AI 能力集成到 .NET 应用中。\n随着 AI 技术的不断进步和 .NET 平台的持续发展，二者的结合将为开发者带来更多可能性。无论是构建智能桌面应用、Web 服务还是跨平台解决方案，图像分类模型都能为项目增添创新价值。希望本文能为你的 AI 之旅提供启发和帮助！\n参考资料\r素材下载地址： https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip Netron工具地址： https://netron.app/ 224x224图像素材： https://www.kaggle.com/datasets/abhinavnayak/catsvdogs-transformed/data tensorflow教程及模型文件和label文件： https://github.com/martinwicke/tensorflow-tutorial Image Classification - Scoring sample： https://github.com/dotnet/machinelearning-samples/blob/main/samples/csharp/getting-started/DeepLearning_ImageClassification_TensorFlow/README.md ML.NET 官方文档： https://dotnet.microsoft.com/apps/machinelearning-ai/ml-dotnet ONNX Model Zoo： https://github.com/onnx/models ","date":"2025-03-21T23:18:58+08:00","image":"http://localhost:1313/img/avatar.jpg","permalink":"http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E5%85%AD%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E5%AF%B9%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/","title":"AI与.NET技术实操系列（六）：基于图像分类模型对图像进行分类"},{"content":"aa这是文章啊啊啊啊啊 啊\n","date":"2025-03-14T23:16:45+08:00","image":"http://localhost:1313/img/avatar.jpg","permalink":"http://localhost:1313/post/%E8%BF%99%E6%98%AF%E6%96%87%E7%AB%A0%E5%95%8A%E5%95%8A%E5%95%8A/%E6%96%87%E7%AB%A0/","title":"0314 Aas"},{"content":"引言\r计算机视觉（Computer Vision, CV）是人工智能领域中最为引人注目的分支之一。从自动驾驶汽车到医疗影像分析，从智能安防系统到虚拟现实体验，计算机视觉的应用无处不在，深刻地改变着我们的生活和工作方式。\n对于.NET开发者而言，掌握计算机视觉技术不仅意味着能够开发出更智能、更具创新性的应用程序，更是在竞争激烈的市场中保持领先的关键。\n❝\nEmgu CV作为OpenCV的.NET包装器，为开发者提供了一个强大的工具，使他们能够在熟悉的.NET环境中轻松应用计算机视觉技术，无需深入学习其他编程语言或平台。其实怎么用这个库倒不是很重要，关键是要转变观念，提升自己对技术的理解力。\n本文将通过一个具体的实践任务——使用Emgu CV进行人脸检测，展示如何在.NET中应用计算机视觉技术。这个任务贴近实际业务需求，能够帮助读者深入理解Emgu CV的使用方法和计算机视觉的基本原理。\nEmgu CV简介\r在深入探讨Emgu CV之前，我们先来初步的了解一下它是什么以及它在计算机视觉应用开发中的作用。\n什么是Emgu CV？\rEmgu CV是一个跨平台的.NET包装器，专门为OpenCV库设计，旨在使.NET开发者能够轻松地使用OpenCV的功能。\nOpenCV（Open Source Computer Vision Library）是一个开源的计算机视觉和机器学习软件库，包含了大量的图像处理、计算机视觉和机器学习算法，被广泛应用于学术研究和工业应用中。\nEmgu CV的出现极大地降低了计算机视觉技术的入门门槛。它不仅支持图像处理、特征检测、对象识别等多种功能，还提供了丰富的API和文档，使得开发者能够快速上手并实现复杂的视觉任务。无论是构建人脸识别系统、实时视频分析工具，还是自动化质量检测系统，Emgu CV都能为开发者提供强有力的支持。\nEmgu CV通过提供C#、VB.NET等.NET平台的接口，允许开发者在.NET环境中调用OpenCV的功能。它支持Windows、Linux、macOS等多个平台，并与.NET Framework、.NET Core和Xamarin等.NET技术栈兼容。Emgu CV不仅封装了OpenCV的核心功能，还提供了一些额外的工具和扩展，如GPU加速、深度学习模块等，使开发者能够构建高性能的计算机视觉应用。\nEmgu CV的优势\r与直接使用OpenCV的C++接口相比，Emgu CV具有以下显著优势：\n易于集成：开发者可以在Visual Studio等IDE中直接使用NuGet包管理器安装Emgu CV，无需手动编译和配置OpenCV库。 丰富的文档和示例：Emgu CV提供了详细的文档和丰富的代码示例，帮助开发者快速上手。 跨平台支持：Emgu CV支持多个操作系统和.NET平台，使开发者能够构建跨平台的计算机视觉应用。 社区支持：Emgu CV拥有活跃的社区，开发者可以在论坛和GitHub上获取帮助和分享经验。 这些优势使Emgu CV成为.NET开发者进行计算机视觉开发的首选工具。无论你是初学者还是经验丰富的开发者，Emgu CV都能帮助你快速实现创意并构建智能应用。\n安装和配置Emgu CV\r在开始使用Emgu CV之前，我们需要安装Emgu CV的NuGet包并配置开发环境。以下是详细的安装和配置步骤。\n安装Emgu CV\rEmgu CV可以通过NuGet包管理器安装。以下是安装Emgu CV核心包的步骤：\n1 dotnet add package Emgu.CVdotnet add package Emgu.CV.runtime.windows 配置开发环境\rEmgu CV的使用需要确保OpenCV的DLL文件在运行时可用。通常，安装“Emgu.CV.runtime.windows”包后，DLL文件会自动复制到输出目录。如果在使用过程中遇到DLL缺失的错误，可以手动将DLL文件复制到项目的输出目录中。\n此外，Emgu CV支持GPU加速，如果你希望使用GPU功能，需要安装相应的CUDA工具包并配置环境变量。详细的配置步骤可以参考Emgu CV的官方文档。\n注意事项\r版本兼容性：Emgu CV的版本与OpenCV的版本相对应，确保你使用的Emgu CV版本与你的项目需求兼容。 平台支持：根据你的目标平台（如Windows、Linux），选择合适的运行时包。 许可证：Emgu CV提供商业和开源两种许可证，开发者需要根据项目需求选择合适的许可证。 完成这些步骤后，你的开发环境就已准备好，可以开始使用Emgu CV进行计算机视觉任务了。\n图像处理基础\r在掌握了Emgu CV的安装和配置后，我们将学习图像处理的基础知识，包括图像的加载、显示、保存以及基本的像素操作。这些基础操作是进行更复杂计算机视觉任务的前提。\n图像加载与显示\rEmgu CV提供了CvInvoke.Imread方法来加载图像文件，并使用CvInvoke.Imshow方法显示图像。以下是一个简单的图像加载和显示示例：\n1 using Emgu.CV;using Emgu.CV.CvEnum;// 加载图像using Emgu.CV.CvEnum;using Emgu.CV;Mat image = CvInvoke.Imread(\u0026#34;input.png\u0026#34;, ImreadModes.Color);if (image.IsEmpty){ Console.WriteLine(\u0026#34;无法加载图像\u0026#34;); return;}Console.WriteLine(\u0026#34;加载图像完成\u0026#34;);// 显示图像CvInvoke.Imshow(\u0026#34;Image\u0026#34;, image);CvInvoke.WaitKey(0);CvInvoke.DestroyAllWindows(); 在这个示例中，我们加载了一个彩色图像并在窗口中显示。ImreadModes.Color指定加载彩色图像，你也可以使用ImreadModes.Grayscale加载灰度图像。\n图像保存\r使用CvInvoke.Imwrite方法可以将图像保存到文件：\n1 CvInvoke.Imwrite(\u0026#34;output.jpg\u0026#34;, image); 访问和修改像素\rEmgu CV允许开发者直接访问和修改图像的像素值。以下是如何访问和修改像素的示例：\n1 using Emgu.CV;using Emgu.CV.Structure;using System.Drawing;string imagePath = \u0026#34;input.png\u0026#34;;Mat image = CvInvoke.Imread(imagePath);if (image.IsEmpty){ Console.WriteLine(\u0026#34;无法加载图像，请检查文件路径是否正确。\u0026#34;); return;}// 定义一个100x100的区域，从坐标(50,50)开始Rectangle roi = new Rectangle(50, 50, 100, 100);// 检查ROI是否超出图像边界if (roi.X + roi.Width \u0026gt; image.Width || roi.Y + roi.Height \u0026gt; image.Height){ Console.WriteLine(\u0026#34;指定的区域超出了图像边界，请调整ROI参数。\u0026#34;); return;}// 获取指定区域的引用Mat region = new Mat(image, roi);// 将该区域设置为红色region.SetTo(new Bgr(0, 0, 255).MCvScalar);// 显示修改后的图像CvInvoke.Imshow(\u0026#34;Modified Image\u0026#34;, image);CvInvoke.WaitKey(); 运行这段代码后，你会看到指定的图片被加载，并且从(50,50)到(149,149)的100x100区域被修改为红色。通过直接操作像素，开发者可以实现各种图像处理效果，如滤波、边缘检测等。\n图像数据表示\r在Emgu CV中，图像通常使用Mat类表示。Mat是一个多维密集数组，可以存储图像数据。开发者可以通过Mat的属性和方法访问图像的尺寸、通道数、数据类型等信息。\n例如：\n1 Console.WriteLine($\u0026#34;图像尺寸: {image.Width}x{image.Height}\u0026#34;);Console.WriteLine($\u0026#34;通道数: {image.NumberOfChannels}\u0026#34;); 理解图像数据的表示方式对于进行高级图像处理和计算机视觉任务至关重要。\n对象检测实践\r在掌握了图像处理的基础后，我们将通过一个具体的对象检测任务——人脸检测，展示如何使用Emgu CV实现计算机视觉应用。人脸检测是计算机视觉中最常见的应用之一，广泛应用于安防监控、身份验证、社交媒体等场景。\n使用Haar级联分类器进行人脸检测\rEmgu CV提供了Haar级联分类器（Haar Cascade Classifier）的人脸检测功能。Haar级联分类器是一种基于机器学习的对象检测方法，通过训练大量正负样本学习对象的特征。\n准备工作\r首先，我们需要一个Haar级联分类器的XML文件。Emgu CV提供了一些预训练的分类器，你可以从OpenCV的GitHub仓库下载，例如haarcascade_frontalface_default.xml。\n实现人脸检测\r以下是使用Haar级联分类器进行人脸检测的代码示例：\n1 // 加载图像using Emgu.CV.CvEnum;using Emgu.CV.Structure;using Emgu.CV;using System.Drawing;// 加载图像Mat image = CvInvoke.Imread(\u0026#34;hejlsberg.png\u0026#34;);if (image.IsEmpty){ Console.WriteLine(\u0026#34;无法加载图像\u0026#34;); return;}// 加载Haar级联分类器CascadeClassifier faceDetector = new CascadeClassifier(\u0026#34;haarcascade_frontalface_default.xml\u0026#34;);// 将图像转换为灰度图像Mat grayImage = new Mat();CvInvoke.CvtColor(image, grayImage, ColorConversion.Bgr2Gray);// 检测人脸Rectangle[] faces = faceDetector.DetectMultiScale(grayImage, 1.1, 10, Size.Empty, Size.Empty);// 在图像上绘制检测到的人脸foreach (Rectangle face in faces){ CvInvoke.Rectangle(image, face, new Bgr(Color.Red).MCvScalar, 2);}// 显示结果CvInvoke.Imshow(\u0026#34;Face Detection\u0026#34;, image);CvInvoke.WaitKey();CvInvoke.DestroyAllWindows(); 代码解析：\n加载图像和分类器：首先，加载输入图像和Haar级联分类器。 灰度转换：人脸检测通常在灰度图像上进行，因此将彩色图像转换为灰度图像。 检测人脸：使用DetectMultiScale方法检测人脸，返回一个矩形数组，表示检测到的人脸位置。 绘制矩形：在原始图像上绘制红色矩形框，标记检测到的人脸。 显示结果：在窗口中显示带有标记的图像。 通过这个示例，你可以看到Emgu CV在对象检测方面的强大功能。开发者可以根据需要调整检测参数，如scaleFactor和minNeighbors，以优化检测效果。\n高级对象检测\r除了Haar级联分类器，Emgu CV还支持更高级的对象检测方法，如基于深度学习的YOLO（You Only Look Once）或SSD（Single Shot MultiBox Detector）。这些方法通常具有更高的准确性和鲁棒性，但需要更多的计算资源。开发者可以根据应用场景选择合适的检测算法。\n计算机视觉在实际应用中的意义和挑战\r计算机视觉技术在实际应用中具有巨大的潜力，但同时也面临着一些挑战。以下是一些需要关注的问题：\n意义\r自动化和智能化：计算机视觉可以自动化许多依赖视觉的任务，如质量检测、监控和导航。 提升用户体验：在社交媒体、游戏和虚拟现实中，计算机视觉技术可以提供更丰富的交互体验。 医疗和科学应用：在医疗影像分析、生物识别等领域，计算机视觉技术可以帮助医生和研究人员更准确地诊断和分析。 挑战\r算法选择：不同的应用场景需要不同的算法，开发者需要根据具体需求选择合适的算法和模型。 性能优化：实时计算机视觉应用对性能要求高，开发者需要优化算法和代码，以确保在有限的资源下实现高效处理。 鲁棒性：计算机视觉系统需要能够在各种光照、角度和遮挡条件下稳定工作，这对算法的鲁棒性提出了挑战。 持续学习：计算机视觉是一个快速发展的领域，新的算法和工具不断涌现。开发者需要保持学习的态度，不断更新知识，以应对新的挑战和机遇。 尽管面临这些挑战，计算机视觉技术仍然为企业和组织带来了巨大的价值。通过自动化视觉任务、提高决策效率和创造新的商业机会，计算机视觉正在重塑各行各业。\n技术伦理\r❝\n我几乎会在我的每篇文章中都会加入这个讨论，因为技术的不可控性必然会带来各种各样的问题甚至是灾难性的问题。因此，我们必须要记住，技术进步应服务于社会福祉。\n计算机视觉技术的快速发展不仅带来了技术上的突破，更引发了对伦理和隐私问题的深刻思考。\n技术与伦理：计算机视觉系统可能在无意中侵犯个人隐私或产生偏见性决策。开发者有责任确保技术的公平性和透明度。 隐私保护：在收集和使用图像数据时，开发者需要遵守相关法律法规，保护用户的隐私权。数据匿名化、加密等技术可以帮助减少隐私风险。 结语\r本文通过介绍Emgu CV的基础知识、安装和配置、图像处理基础、对象检测实践以及实际应用中的意义和挑战，为.NET开发者提供了一个全面而深入的指南。Emgu CV作为OpenCV的.NET包装器，为开发者提供了一个强大的工具，使他们能够在.NET环境中轻松应用计算机视觉技术。\n希望本文能够激发你的兴趣，帮助你开启计算机视觉在.NET中的探索之旅，也希望因此你可以对.NET充满信息，未来的.NET一定会更好，当然在人工智能背景下，Python的重要性不言而喻，我们也要对Python有足够的了解，通过.NET + Python提升自己的竞争力。\n","date":"2025-03-14T23:16:45+08:00","image":"http://localhost:1313/img/avatar.jpg","permalink":"http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%B8%83%E4%BD%BF%E7%94%A8emgu-cv%E8%BF%9B%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%93%8D%E4%BD%9C/","title":"AI与.NET技术实操系列（七）：使用Emgu CV进行计算机视觉操作"},{"content":"引言\r在当今这个数据爆炸的时代，信息的快速存储与高效检索已经成为技术领域的核心挑战。随着人工智能（AI）和机器学习（ML）的迅猛发展，向量存储和相似性搜索技术逐渐崭露头角，成为处理海量数据的利器。对于使用 .NET 的开发者来说，掌握这些技术不仅意味着能够开发出更智能、更高效的应用，更是在信息洪流中保持竞争力的关键。借助向量存储，我们可以将复杂的数据（如文本、图像或音频）转化为高维向量，通过相似性搜索快速找到与查询最相关的内容，从而大幅提升信息检索的精度和效率。\n向量存储和相似性搜索的应用潜力令人振奋。从智能推荐系统到图像检索工具，再到自然语言处理（NLP）中的语义搜索，这些技术正在重塑我们与数据的交互方式。通过在向量空间中使用距离度量（如余弦相似度或欧氏距离），开发者可以实现高效的匹配机制，为用户提供个性化的体验。然而，技术的实现并非一帆风顺，高维数据的存储、计算资源的优化、索引结构的构建以及实时性能的保障，都是开发者需要面对的难题。\n本文将通过一个具体的实践任务——实现一个简单的文档相似性搜索系统，深入探讨如何在 .NET 中应用向量存储和相似性搜索技术。我们将从基础知识入手，逐步介绍向量存储的选择与使用，并通过清晰的代码示例，引导读者完成一个功能完备的搜索应用。\n希望本文能为你打开向量存储的大门，激发你在 .NET 开发中探索智能技术的热情。\n向量存储和相似性搜索基础知识\r在进入实践之前，我们先来梳理向量存储和相似性搜索的基本概念及其工作原理。\n什么是向量存储？\r向量存储（Vector Store）是一种专门设计用于存储和检索高维向量的数据库系统。在 AI 和 ML 领域，数据通常被转化为高维向量（称为 embeddings），以捕捉其语义或特征信息。例如，一段文本可以通过预训练模型（如 BERT）转换为一个 384 维的向量，图像可以通过卷积神经网络提取特征向量。向量存储通过优化这些高维数据的存储结构和查询机制，支持快速的相似性搜索，帮助开发者高效地找到与查询最相关的内容。\n什么是相似性搜索？\r相似性搜索（Similarity Search）是一种旨在找到与查询项最相似的项的搜索技术。在向量空间中，相似性通常通过距离度量来衡量，常见的度量方法包括：\n余弦相似度：计算两个向量夹角的余弦值，反映方向的相似性，广泛用于文本搜索。 欧氏距离：计算两个向量间的直线距离，常用于图像和数值数据的匹配。 曼哈顿距离：计算向量在各维度上的差值之和，适用于特定场景。 通过这些度量，相似性搜索能够在海量数据中快速定位与查询最接近的结果，极大地提升了搜索效率。\n向量存储的工作原理\r向量存储依赖以下核心技术来实现高效的存储和查询：\n索引结构：如 KD-Tree、HNSW（层次可导航小世界图），用于加速相似性搜索。 近似最近邻（ANN）：通过牺牲少量精度换取更高的搜索速度，适用于大规模数据集。 分布式架构：支持数据的并行处理和存储，满足高并发需求。 这些技术的结合使得向量存储能够应对高维数据的挑战，为实时应用提供强大支持。\n选择和使用向量存储\r在 .NET 中实现向量存储和相似性搜索，开发者可以选择多种工具和服务。以下是几个常见选项：\nMilvus\rMilvus 是一个开源的向量数据库，专为高维向量存储和搜索设计。它支持多种索引类型（如 HNSW、IVF）和距离度量，提供高性能的搜索能力。Milvus 可通过 RESTful API 或客户端 SDK 与 .NET 集成。\nqDrant\rqDrant 是一个轻量级向量数据库，适合中小规模应用。它支持实时数据插入和搜索，提供简单易用的 API，方便快速上手。\nAzure AI Search\rAzure AI Search 是微软提供的云端搜索服务，支持向量搜索和全文搜索。它与 Azure 生态无缝集成，适合企业级应用。\n本文将以 Milvus 为例，展示如何在 .NET 中实现向量存储和搜索。Milvus 以其高性能和灵活性，成为许多 AI 项目的首选。\n实现文档相似性搜索系统\r为了帮助读者深入理解向量存储的实际应用，我们将实现一个简单的文档相似性搜索系统。该系统能够将文档转换为向量，存储到 Milvus 中，并支持用户查询相似文档。\n系统设计\r系统的核心组件包括：\n文档向量化：使用预训练模型将文本转换为向量。 向量存储：将向量存储到 Milvus 并构建索引。 相似性搜索：根据用户查询生成向量并搜索相似结果。 结果展示：返回最相似的文档。 我们将使用 SentenceTransformers 生成向量，并通过 Milvus 实现存储和搜索。\n准备工作\r在开始之前，需要完成以下准备：\n创建Milvus-Test文件夹，并新建如下文件夹： 下载milvus-standalone-docker-compose.yml，重命名成docker-compose.yml后移入到刚刚创建好的Milvus-Test文件夹中 安装 Milvus：使用 Docker 部署 Milvus（docker compose up -d） 实现步骤\r1. 文档向量化\r首先，使用 SentenceTransformers 将文档转换为向量（需 Python 环境）：\n1 from sentence_transformers import SentenceTransformermodel = SentenceTransformer(\u0026#39;all-MiniLM-L6-v2\u0026#39;)documents = [\u0026#34;This is document one.\u0026#34;, \u0026#34;This is document two.\u0026#34;, \u0026#34;This is document three.\u0026#34;]embeddings = model.encode(documents) embeddings 是包含每个文档向量的数组（维度为 384）。\n2. 存储向量到 Milvus\r安装Nuget包：\n1 dotnet add package Milvus.Client --version 2.3.0-preview.1 使用 C# 检测 Milvus 是否正常运行的代码：\n1 MilvusClient milvusClient = new MilvusClient(\u0026#34;{Endpoint}\u0026#34;, \u0026#34;{Port}\u0026#34;, \u0026#34;{Username}\u0026#34;, \u0026#34;{Password}\u0026#34;, \u0026#34;{Database}(Optional)\u0026#34;);MilvusHealthState result = await milvusClient.HealthAsync(); 使用 C# 调用 Milvus 创建集合代码：\n1 string collectionName = \u0026#34;book\u0026#34;;MilvusCollection collection = milvusClient.GetCollection(collectionName);//Check if this collection existsvar hasCollection = await milvusClient.HasCollectionAsync(collectionName);if(hasCollection){ await collection.DropAsync(); Console.WriteLine(\u0026#34;Drop collection {0}\u0026#34;,collectionName);}await milvusClient.CreateCollectionAsync( collectionName, new[] { FieldSchema.Create\u0026lt;long\u0026gt;(\u0026#34;book_id\u0026#34;, isPrimaryKey:true), FieldSchema.Create\u0026lt;long\u0026gt;(\u0026#34;word_count\u0026#34;), FieldSchema.CreateVarchar(\u0026#34;book_name\u0026#34;, 256), FieldSchema.CreateFloatVector(\u0026#34;book_intro\u0026#34;, 2L) } ); 使用 C# 调用 Milvus 插入向量代码：\n1 Random ran = new ();List\u0026lt;long\u0026gt; bookIds = new ();List\u0026lt;long\u0026gt; wordCounts = new ();List\u0026lt;ReadOnlyMemory\u0026lt;float\u0026gt;\u0026gt; bookIntros = new ();List\u0026lt;string\u0026gt; bookNames = new ();for (long i = 0L; i \u0026lt; 2000; ++i){ bookIds.Add(i); wordCounts.Add(i + 10000); bookNames.Add($\u0026#34;Book Name {i}\u0026#34;); float[] vector = new float[2]; for (int k = 0; k \u0026lt; 2; ++k) { vector[k] = ran.Next(); } bookIntros.Add(vector);}MilvusCollection collection = milvusClient.GetCollection(collectionName);MutationResult result = await collection.InsertAsync( new FieldData[] { FieldData.Create(\u0026#34;book_id\u0026#34;, bookIds), FieldData.Create(\u0026#34;word_count\u0026#34;, wordCounts), FieldData.Create(\u0026#34;book_name\u0026#34;, bookNames), FieldData.CreateFloatVector(\u0026#34;book_intro\u0026#34;, bookIntros), });// Check resultConsole.WriteLine(\u0026#34;Insert count:{0},\u0026#34;, result.InsertCount); 3. 构建索引\r为加速搜索，需在集合上构建索引：\n1 MilvusCollection collection = milvusClient.GetCollection(collectionName);await collection.CreateIndexAsync( \u0026#34;book_intro\u0026#34;, //MilvusIndexType.IVF_FLAT,//Use MilvusIndexType.IVF_FLAT. IndexType.AutoIndex,//Use MilvusIndexType.AUTOINDEX when you are using zilliz cloud. SimilarityMetricType.L2);// Check index statusIList\u0026lt;MilvusIndexInfo\u0026gt; indexInfos = await collection.DescribeIndexAsync(\u0026#34;book_intro\u0026#34;);foreach(var info in indexInfos){ Console.WriteLine(\u0026#34;FieldName:{0}, IndexName:{1}, IndexId:{2}\u0026#34;, info.FieldName , info.IndexName,info.IndexId);}// Then load itawait collection.LoadAsync();} 4. 实现相似性搜索\r根据用户查询搜索相似文档：\n1 List\u0026lt;string\u0026gt; search_output_fields = new() { \u0026#34;book_id\u0026#34; };List\u0026lt;List\u0026lt;float\u0026gt;\u0026gt; search_vectors = new() { new() { 0.1f, 0.2f } };SearchResults searchResult = await collection.SearchAsync( \u0026#34;book_intro\u0026#34;, new ReadOnlyMemory\u0026lt;float\u0026gt;[] { new[] { 0.1f, 0.2f } }, SimilarityMetricType.L2, limit: 2);// Querystring expr = \u0026#34;book_id in [2,4,6,8]\u0026#34;;QueryParameters queryParameters = new ();queryParameters.OutputFields.Add(\u0026#34;book_id\u0026#34;);queryParameters.OutputFields.Add(\u0026#34;word_count\u0026#34;);IReadOnlyList\u0026lt;FieldData\u0026gt; queryResult = await collection.QueryAsync( expr, queryParameters); 5. 集成到应用\r❝\n后面要做的事情就很多了，大家可以自行发挥，当然有兴趣的朋友还可以安装attu ui界面作为 Milvus的客户端，小编并没有安装，因此我截取官方图片让大家看一下，地址为：https://github.com/zilliztech/attu/releases。\n实际应用中的意义与挑战\r意义\r提升用户体验：语义搜索提供更精准的结果。 多模态支持：可扩展到图像、音频等领域。 效率优化：加速信息检索和决策。 挑战\r资源需求：高维数据需要大量计算和存储资源。 索引优化：需平衡速度与精度。 实时性：高并发场景下的性能保障。 结语\r本文通过理论与实践结合，展示了在 .NET 中实现向量存储和相似性搜索的方法。希望你能从中获得启发，在智能应用的浪潮中找到自己的位置。向量存储的潜力无限，让我们共同探索这一领域，在技术的海洋里尽情驰骋！\n参考链接:\nhttps://www.nuget.org/packages/Milvus.Client/ https://github.com/zilliztech/attu/blob/main/.github/images/collection_overview.png ","date":"2025-03-14T23:16:45+08:00","image":"http://localhost:1313/img/avatar.jpg","permalink":"http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/","title":"AI与.NET技术实操系列（五）：向量存储与相似性搜索在 .NET 中的实现"},{"content":"无线投屏协议是指通过无线网络将智能移动设备的屏幕图像和声音实时传输至另一台显示设备上，实现内容的同屏展示的技术标准。目前，市场上存在多种无线投屏协议，其中五大主流的无线投屏协议包括Miracast、AirPlay、DLNA、Chromecast以及WiDi。以下是对这五大协议的详细介绍：\n1. Miracast\r技术特点：由Wi-Fi联盟制定，以WIFI连接为基础的无线投屏协议，支持Android和Windows设备。Miracast无线投屏是兼容性最广的投屏协议，国内大多数Android手机、智能电视都支持Miracast投屏协议。Miracast使用Wi-Fi Direct技术，设备之间直接建立连接，无需依赖路由器或互联网\n适用设备：Android 5.0以上手机、Windows 8/10电脑。\n限制：传输基于UDP协议，易受干扰，可能导致接收端画质问题；不同Android设备开启Miracast的方式不一致，推广困难。\n2. AirPlay\r技术特点：苹果开发的一种无线技术，通过Wi-Fi将iPhone、iPad等iOS设备上的音视频、图片通过无线方式传输到支持AirPlay的设备，如Apple TV、智能电视等。AirPlay支持推送和镜像两种模式，具有高清、低延迟、易用等特点。\n操作方式：在iOS设备上呼出控制中心，选择“屏幕镜像”并连接目标设备。\n限制：要求苹果设备与投屏设备在同一局域网内，不支持跨网段使用。\n3. DLNA\r技术特点：由索尼、英特尔、微软等发起的一套PC、移动设备、消费电器之间互联互通的协议。DLNA只支持推送模式，具有标准化、跨平台、易扩展等特点。\n适用场景：家庭影院，不太适合企业环境。\n优势：画质无损，对网络要求较高。\n4. Chromecast\r技术特点：谷歌开发的无线投屏技术，需要使用一个小型的硬件设备插入电视或显示器的HDMI接口，然后通过WiFi与手机或电脑连接，实现视频、音乐、网页等内容的投屏。Chromecast支持推送和镜像两种模式，具有智能化、云端化、开放性等特点。\n优势：体验更接近于DLNA，但比DLNA更加灵活和智能。\n5. WiDi\r技术特点：全称为Intel Wireless Display（无线高清技术），是Intel公司开发的一种无线投屏技术。它允许用户通过WiFi信号将电脑屏幕的内容无线传输到支持WiDi的显示设备上。\n优势：无需安装软件，即可实现无线投屏，使用便捷。\n限制：需要发射端设备具备HDMI输出接口，限制了使用范围。\n综上所述，这五大无线投屏协议各有其技术特点和适用场景。在选择投屏协议时，用户应根据自身设备、网络环境以及使用需求来做出合理的选择。\n参考链接：\n","date":"2025-03-14T23:16:45+08:00","image":"http://localhost:1313/post/%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE-miracastairplaydlnachromecast%E4%BB%A5%E5%8F%8Awidi%E4%BA%94%E5%A4%A7%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/images/LDQ1bOKTfoNTycxnhgscFidkn1b_hu_894ebfa7c9888d80.png","permalink":"http://localhost:1313/post/%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE-miracastairplaydlnachromecast%E4%BB%A5%E5%8F%8Awidi%E4%BA%94%E5%A4%A7%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/","title":"投屏协议 Miracast、AirPlay、DLNA、Chromecast以及WiDi五大投屏协议详细介绍"},{"content":"","date":"2025-03-14T22:57:04+08:00","image":"http://localhost:1313/img/avatar.jpg","permalink":"http://localhost:1313/post/0314-%E8%BF%99%E6%98%AF%E7%9A%84%E5%95%8A%E7%9A%84%E5%95%8A/","title":"0314 这是的啊的啊"},{"content":"正文测试\r。\n奥斯特洛夫斯基曾经说过，共同的事业，共同的斗争，可以使人们产生忍受一切的力量。　带着这句话，我们还要更加慎重的审视这个问题： 一般来讲，我们都必须务必慎重的考虑考虑。 既然如此， 这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 带着这些问题，我们来审视一下学生会退会。 我认为， 我认为， 在这种困难的抉择下，本人思来想去，寝食难安。 问题的关键究竟为何？ 每个人都不得不面对这些问题。 在面对这种问题时， 要想清楚，学生会退会，到底是一种怎么样的存在。 我认为， 既然如此， 每个人都不得不面对这些问题。 在面对这种问题时， 那么， 我认为， 学生会退会因何而发生。\n引用\r思念是最暖的忧伤像一双翅膀\n让我停不了飞不远在过往游荡\n不告而别的你 就算为了我着想\n这么沉痛的呵护 我怎么能翱翔\n最暖的憂傷 - 田馥甄\n图片\r1 2 3 ![Photo by Florian Klauer on Unsplash](florian-klauer-nptLmg6jqDo-unsplash.jpg) ![Photo by Luca Bravo on Unsplash](luca-bravo-alS7ewQ41M8-unsplash.jpg) ![Photo by Helena Hertz on Unsplash](helena-hertz-wWZzXlDpMog-unsplash.jpg) ![Photo by Hudai Gayiran on Unsplash](hudai-gayiran-3Od_VKcDEAA-unsplash.jpg) 相册语法来自 Typlog\n","date":"2025-03-14T22:46:28+08:00","image":"http://localhost:1313/img/avatar.jpg","permalink":"http://localhost:1313/post/chinese-testa/","title":"0314 创建新的文章22"},{"content":"1. 安装Hugo\r使用Chocolatey搭建\n安装 https://chocolatey.org/install（包管理器）。 PowerShell执行管理员身份下面命令先安装Chocolatey\n1 Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString(\u0026#39;https://community.chocolatey.org/install.ps1\u0026#39;)) 命令行执行： 1 choco install hugo -confirm #安装hugo 安装hugo拓展版\n1 choco install hugo-extended -y --confirm #安装Hugo 扩展版（必需）​ 2. 创建 Hugo 项目\r初始化项目 执行如下命令创建Hugo项目\n1 2 3 4 5 # 1. 创建 Hugo 项目 hugo new site my-blog cd my-blog # 2. 初始化 Git 仓库 git init 添加主题子模块 1 2 3 4 5 # 3. 添加主题子模块（必须在项目根目录执行） git submodule add https://github.com/adityatelange/hugo-PaperMod themes/PaperMod # 4. 验证 ls themes/PaperMod # 应看到主题文件 cat .gitmodules # 应显示子模块配置 在添加主题的时候由于网速比较慢，所有经常下载主题失败。我使用如下方式添加主题，先 clone主题下来，在执行submodule。\n1 2 3 #添加主题子模块（必须在项目根目录执行） git clone https://github.com/adityatelange/hugo-PaperMod themes/PaperMod git submodule add https://github.com/adityatelange/hugo-PaperMod themes/PaperMod 更多添加主题：从https://themes.gohugo.io/下载喜欢的主题，直接拷贝至 technical_blog/themes 目录，并修改配置文件 hugo.toml，删除 url 字段，添加 theme=\u0026rsquo; 主题名 \u0026lsquo;。\n配置主题 修改 hugo.toml 文件，Hugo支持TOML、YAML和JSON三种格式配置文件，优先级为hugo.toml \u0026gt; hugo.yaml \u0026gt; hugo.json\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 baseURL = \u0026#39;https://panwangvie.github.io\u0026#39; languageCode = \u0026#39;zh-cn\u0026#39; title = \u0026#39;My New Hugo Site\u0026#39; theme = \u0026#34;PaperMod\u0026#34; #使用的主题 defaultContentLanguage = \u0026#34;zh-cn\u0026#34; # 新增此行，设置默认语言为中文 [build] publishDir = \u0026#34;public\u0026#34; # 中文语言配置 [languages.zh-cn] weight = 1 title = \u0026#34;我的博客\u0026#34; languageName = \u0026#34;中文\u0026#34; [params] dateFormat = \u0026#34;2006-01-02\u0026#34; [params.social] GitHub = \u0026#34;https://github.com/panwangvie\u0026#34; 3. 启动本地服务器验证\r确保配置正确后，启动 Hugo 本地预览：\n1 2 3 hugo new posts/hello-world.md #创建一个md hugo server -D #运行服务 hugo -D --minify 如果成功，浏览器访问 http://localhost:1313 会显示基于 PaperMod 主题的博客。 4. 部署到GitHub\r发布网站：执行 hugo 命令在项目根目录的 public 目录中创建整个静态站点。\n部署到 GitHub：在 GitHub 上创建名为 {用户名}.github.io 的仓库，将本地项目的 public 文件夹中的内容推送到该仓库，即可通过 https://{用户名}.github.io 访问博客。\n1 2 3 4 git add . git commit -m \u0026#34;初始化个人博客\u0026#34; git remote add origin https://github.com/\u0026lt;用户名\u0026gt;/\u0026lt;用户名\u0026gt;.github.io.git git push -u origin main 我搭建的Demo https://panwangvie.github.io/\n5. 博客评论系统的使用\r博客中的评论系统是很重要的。这里我使用的是 Stack 模板支持的 Waline，搭建很简单，可以参考 Waline 官方指南。\n配置 Waline 则可以参考这篇博客 hugo：添加评论功能（Waline） - 建站指南，我的 Waline 配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # Waline 评论系统配置，参考：https://waline.js.org/en/reference/component.html waline: waline: # 这里填你的vercel服务器地址。 # vercel自定义域名会和cloudflare会冲突导致无限301,所以干脆直接用送的域名了 # 注意要部署总域名，而不是最新部署的版本域名（中间有一段随机英文字符的），否则会报 401 Unauthorized serverURL: https://waline-你的用户名.vercel.app/ lang: zh-CN # 文章浏览量统计，在新版waline中已更名为pageview属性，貌似用不了了 # 填入false代表不启用，填入字符串的时候会作为css选择器 visitor: false # 头像来源，在V2中已移除该属性 avatar: emoji: #表情包地址详见https://waline.js.org/guide/features/emoji.html，饿了么提供的国内镜像（将 unpkg.com 替换为 npm.elemecdn.com） - https://npm.elemecdn.com/@waline/emojis@1.1.0/bilibili - https://npm.elemecdn.com/@waline/emojis@1.1.0/bmoji - https://npm.elemecdn.com/@waline/emojis@1.1.0/weibo - https://npm.elemecdn.com/@waline/emojis@1.2.0/qq # 回复时必填的内容 requiredMeta: - name - email - url # 评论框的默认的文字 placeholder: 欢迎留下宝贵的评论！ # 自定义语言设置，参考https://waline.js.org/cookbook/customize/locale.html#locale-%E9%80%89%E9%A1%B9 locale: admin: 会长 sofa: 还没有人评论哦！快来抢沙发吧~ 另外 emoji 官方提供了许多预设，可以查看预设列表自行选择。\n但是官方提供的预设使用的 unpkg 经常会被墙而导致无法正常访问，这里推荐替换为饿了么提供的国内镜像（将 unpkg.com 替换为 npm.elemecdn.com）\n6. 参考案例与资源\r开源博客模板：https://github.com/adityatelange/hugo-PaperMod\nHugo 官方文档：https://gohugo.io/documentation/\nGitHub Actions 配置示例：https://github.com/peaceiris/actions-hugo\n其他安装教程： https://baize.wiki/blog/how-to-build-blog/\n","date":"2025-03-14T21:58:59+08:00","image":"http://localhost:1313/post/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99hugo+stack%E4%B8%BB%E9%A2%98%E8%BD%BB%E6%9D%BE%E6%90%AD%E5%BB%BA/images/image-6_hu_bda22fe06b0319ab.png","permalink":"http://localhost:1313/post/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99hugo+stack%E4%B8%BB%E9%A2%98%E8%BD%BB%E6%9D%BE%E6%90%AD%E5%BB%BA/","title":"搭建个人网站——Hugo+Stack主题轻松搭建"},{"content":"\raaaaaa\n","date":"2025-03-14T00:00:00Z","image":"http://localhost:1313/img/avatar.jpg","permalink":"http://localhost:1313/post/0314-%E5%88%9B%E5%BB%BA%E6%96%B0%E7%9A%84%E6%96%87%E7%AB%A0/","title":"0314 创建新的文章"},{"content":"Hugo ships with several Built-in Shortcodes for rich content, along with a Privacy Config and a set of Simple Shortcodes that enable static and no-JS versions of various social media embeds.\nYouTube Privacy Enhanced Shortcode\rVimeo Simple Shortcode\rbilibilibi Shortcode\rGitlab Snippets Shortcode\rQuote Shortcode\rStack adds a quote shortcode. For example:\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n― A famous person, The book they wrote Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n― Anonymous book Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n― Some book Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n― Somebody","date":"2019-03-10T00:00:00Z","permalink":"http://localhost:1313/post/rich-content/","title":"Rich Content"},{"content":"Hugo ships with several Built-in Shortcodes for rich content, along with a Privacy Config and a set of Simple Shortcodes that enable static and no-JS versions of various social media embeds.\nYouTube Privacy Enhanced Shortcode\rVimeo Simple Shortcode\rbilibilibi Shortcode\rGitlab Snippets Shortcode\rQuote Shortcode\rStack adds a quote shortcode. For example:\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n― A famous person, The book they wrote Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n― Anonymous book Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n― Some book Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n― Somebody","date":"2019-03-10T00:00:00Z","permalink":"http://localhost:1313/post/rich-contenta/","title":"Rich Content"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings\rThe following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1\rH2\rH3\rH4\rH5\rH6\rParagraph\rXerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes\rThe blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution\rTiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution\rDon\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables\rTables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables\rItalics Bold Code italics bold code A B C D E F Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien Code Blocks\rCode block with backticks\r1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces\r\u0026lt;!doctype html\u0026gt;\r\u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt;\r\u0026lt;head\u0026gt;\r\u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt;\r\u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt;\r\u0026lt;/head\u0026gt;\r\u0026lt;body\u0026gt;\r\u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt;\r\u0026lt;/body\u0026gt;\r\u0026lt;/html\u0026gt;\rCode block with Hugo\u0026rsquo;s internal highlight shortcode\r1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Diff code block\r1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] List Types\rOrdered List\rFirst item Second item Third item Unordered List\rList item Another item And another item Nested list\rFruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark\rGIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL + ALT + Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nHyperlinked image\rThe above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-03-09T00:00:00Z","image":"http://localhost:1313/matt-le-SJSpo9hQf7s-unsplash.jpg","permalink":"http://localhost:1313/post/markdown-syntax/","title":"markdown-syntax"},{"content":"Lorem est tota propiore conpellat pectoribus de pectora summo.\nRedit teque digerit hominumque toris verebor lumina non cervice subde tollit usus habet Arctonque, furores quas nec ferunt. Quoque montibus nunc caluere tempus inhospita parcite confusaque translucet patri vestro qui optatis lumine cognoscere flos nubis! Fronde ipsamque patulos Dryopen deorum.\nExierant elisi ambit vivere dedere Duce pollice Eris modo Spargitque ferrea quos palude Rursus nulli murmur; hastile inridet ut ab gravi sententia! Nomine potitus silentia flumen, sustinet placuit petis in dilapsa erat sunt. Atria tractus malis.\nComas hunc haec pietate fetum procerum dixit Post torum vates letum Tiresia Flumen querellas Arcanaque montibus omnes Quidem et Vagus elidunt\rThe Van de Graaf Canon\nMane refeci capiebant unda mulcebat\rVicta caducifer, malo vulnere contra dicere aurato, ludit regale, voca! Retorsit colit est profanae esse virescere furit nec; iaculi matertera et visa est, viribus. Divesque creatis, tecta novat collumque vulnus est, parvas. Faces illo pepulere tempus adest. Tendit flamma, ab opes virum sustinet, sidus sequendo urbis.\nIubar proles corpore raptos vero auctor imperium; sed et huic: manus caeli Lelegas tu lux. Verbis obstitit intus oblectamina fixis linguisque ausus sperare Echionides cornuaque tenent clausit possit. Omnia putatur. Praeteritae refert ausus; ferebant e primus lora nutat, vici quae mea ipse. Et iter nil spectatae vulnus haerentia iuste et exercebat, sui et.\nEurytus Hector, materna ipsumque ut Politen, nec, nate, ignari, vernum cohaesit sequitur. Vel mitis temploque vocatus, inque alis, oculos nomen non silvis corpore coniunx ne displicet illa. Crescunt non unus, vidit visa quantum inmiti flumina mortis facto sic: undique a alios vincula sunt iactata abdita! Suspenderat ego fuit tendit: luna, ante urbem Propoetides parte.\n","date":"2019-03-09T00:00:00Z","image":"http://localhost:1313/post/placeholder-text/matt-le-SJSpo9hQf7s-unsplash_hu_c1ca39d792aee4ab.jpg","permalink":"http://localhost:1313/post/placeholder-text/","title":"Placeholder Text"},{"content":"Emoji can be enabled in a Hugo project in a number of ways.\nThe emojify function can be called directly in templates or Inline Shortcodes.\nTo enable emoji globally, set enableEmoji to true in your site\u0026rsquo;s configuration and then you can type emoji shorthand codes directly in content files; e.g.\n🙈 :see_no_evil: 🙉 :hear_no_evil: 🙊 :speak_no_evil:\nThe Emoji cheat sheet is a useful reference for emoji shorthand codes.\nN.B. The above steps enable Unicode Standard emoji characters and sequences in Hugo, however the rendering of these glyphs depends on the browser and the platform. To style the emoji you can either use a third party emoji font or a font stack; e.g.\n1 2 3 .emoji { font-family: Apple Color Emoji, Segoe UI Emoji, NotoColorEmoji, Segoe UI Symbol, Android Emoji, EmojiSymbols; } ","date":"2019-03-05T00:00:00Z","image":"http://localhost:1313/post/enjoy/the-creative-exchange-d2zvqp3fpro-unsplash_hu_27b8954607cdb515.jpg","permalink":"http://localhost:1313/post/enjoy/","title":"Emoji Support"},{"content":"前言 博客搭建完成之后，可以添加一个评论系统，方便读者反馈交流。这里选用的是 Waline，因为 Hugo Stack 主题支持 Waline，所以配置起来也会方便不少。同时Waline，只需几个步骤，就可以在你的网站中启用 Waline 提供评论服务。\n所以，本文将要介绍给博客添加Waline评论系统，并配置以自己的域名邮箱接收博客评论的邮箱通知提醒功能。\n由于Waline文档写的挺详细的，所以直接照搬过来，并针对自身的需求做些改动。\nLeanCloud 设置 (数据库) 登录 或 注册 LeanCloud 国际版 并进入 控制台\n点击左上角 创建应用 并起一个你喜欢的名字 (选择免费的开发版):\n创建应用\n进入应用，选择左下角的 设置 \u0026gt; 应用 Key。你可以看到你的 APP ID,APP Key 和 Master Key。请记录它们，以便后续使用。\nID 和 Key\n注意！如果使用 Leancloud 国内版 (leancloud.cn) 需要备案，推荐使用国际版 (leancloud.app)。否则，你需要为应用额外绑定已备案的域名，同时购买独立 IP 并完成备案接入。\nVercel 部署 (服务端) Vercel\n点击上方按钮，跳转至 Vercel 进行 Server 端部署。\n注：如果你未登录的话，Vercel 会让你注册或登录，请使用 GitHub 账户进行快捷登录。\n输入一个你喜欢的 Vercel 项目名称并点击 Create 继续:\n创建项目\n此时 Vercel 会基于 Waline 模板帮助你新建并初始化仓库，仓库名为你之前输入的项目名。\ndeploy\n一两分钟后，满屏的烟花会庆祝你部署成功。此时点击 Go to Dashboard 可以跳转到应用的控制台。\ndeploy\n点击顶部的 Settings - Environment Variables 进入环境变量配置页，并配置三个环境变量 LEAN_ID, LEAN_KEY 和 LEAN_MASTER_KEY 。它们的值分别对应上一步在 LeanCloud 中获得的 APP ID, APP KEY, Master Key。\n设置环境变量\n环境变量配置完成之后点击顶部的 Deployments 点击顶部最新的一次部署右侧的 Redeploy 按钮进行重新部署。该步骤是为了让刚才设置的环境变量生效。\nredeploy\n此时会跳转到 Overview 界面开始部署，等待片刻后 STATUS 会变成 Ready。此时请点击 Visit ，即可跳转到部署好的网站地址，此地址即为你的服务端地址。 redeploy success\nStack 主题启用Waline 在 config/_default/params.toml 配置文件里找到这一区块：\n1 2 3 4\nComments\r[comments] enabled = true provider = \u0026ldquo;waline\u0026rdquo; Copy 将 enabled 改完 true，provider 改为 waline，然后在 comments.waline 区块设置 waline 的相关配置：\n1 2 3 4 5 6 7 8 9 10 [comments.waline] serverURL = \u0026ldquo;your-server-url\u0026rdquo; lang = \u0026ldquo;zh-CN\u0026rdquo; avatar = \u0026quot;\u0026quot; emoji = [\u0026ldquo;https://cdn.jsdelivr.net/gh/walinejs/emojis/weibo\u0026rdquo;] requiredMeta = [\u0026ldquo;nick\u0026rdquo;, \u0026ldquo;mail\u0026rdquo;, \u0026ldquo;url\u0026rdquo;]\n[comments.waline.locale] admin = \u0026ldquo;Admin\u0026rdquo; placeholder = \u0026ldquo;评论区掩码\u0026rdquo; Copy serverURL 改为你的 vercel 的服务端地址即可。\n评论服务此时就会在你的网站上成功运行 🎉\n评论管理 (管理端) 部署完成后，请访问 /ui/register 进行注册。首个注册的人会被设定成管理员。 管理员登陆后，即可看到评论管理界面。在这里可以修改、标记或删除评论。 用户也可通过评论框注册账号，登陆后会跳转到自己的档案页。 评论邮箱通知 当网站有用户发布评论或者用户回复评论时，Waline 支持对博主和回复评论作者进行通知，当访客的评论收到回复时，我们会对访客进行邮件通知。\n邮件通知需要配置以下环境变量:\nSMTP_SERVICE: SMTP 邮件发送服务提供商。\n提示\n你可以在 这里 查看所有支持的运营商。\n如果你的运营商不受支持，你必须填写 SMTP_HOST 和 SMTP_PORT。\nSMTP_HOST: SMTP 服务器地址，一般可以在邮箱的设置中找到。 SMTP_PORT: SMTP 服务器端口，一般可以在邮箱的设置中找到。 SMTP_USER: SMTP 邮件发送服务的用户名，一般为登录邮箱。\nSMTP_PASS: SMTP 邮件发送服务的密码，一般为邮箱登录密码，部分邮箱(例如 163)是单独的 SMTP 密码。\nSMTP_SECURE: 是否使用 SSL 连接 SMTP。\nSITE_NAME: 网站名称，用于在消息中显示。\nSITE_URL: 网站地址，用于在消息中显示。\nAUTHOR_EMAIL: 博主邮箱，用来接收新评论通知。如果是博主发布的评论则不进行提醒通知。\nSENDER_NAME: 自定义发送邮件的发件人\nSENDER_EMAIL: 自定义发送邮件的发件地址\n这里我们选择的是 Brevo，关于 Brevo 的配置参见免费搭建属于自己的域名个性邮箱 (limuran.top)。\n1 2 3 4 5 \u0026ldquo;SendinBlue\u0026rdquo;: { \u0026ldquo;aliases\u0026rdquo;: [\u0026ldquo;Brevo\u0026rdquo;], \u0026ldquo;host\u0026rdquo;: \u0026ldquo;smtp-relay.brevo.com\u0026rdquo;, \u0026ldquo;port\u0026rdquo;: 587 } Copy 当你创建好后，前往 Vercel 继续添加环境变量。\n所需环境变量如下表：\nKey\tValue\tComment（用于解释作用） SMTP_SERVICE\tSendinBlue\tBrevo 对应的提供商是 SendinBlue SMTP_USER\tBrevo Login 对应的邮箱名 SMTP_PASS\tBrevo 的 SMTP key value SITE_NAME\t网站名称 SITE_URL\t网站地址 AUTHOR_EMAIL\t作者邮箱 SENDER_NAME\t发件人昵称 SENDER_EMAIL\t发件人域名邮箱（如：limuran@limuran.top） 空着的 Value 自行添加。\nimage-20231216221301059\n然后再点击 Redeploy 按钮进行重新部署，即可生效，之后就可测试了。\n视频教程 以下是热心用户制作的视频教程，以上操作不清楚的也可以参考一二。\nWaline 部署教程（快速上手） A BiliBili video\n使用 Vercel 简单地部署 Waline 评论系统 A BiliBili video\nHugo Hugo Stack Comment Hugo Waline\n","date":"0001-01-01T00:00:00Z","permalink":"http://localhost:1313/post/hugo-stack%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%B7%BB%E5%8A%A0waline%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F/hugo-stack%E4%B8%BB%E9%A2%98%E5%8D%9A%E5%AE%A2%E6%B7%BB%E5%8A%A0waline%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F/","title":""},{"content":"Mathematical notation in a Hugo project can be enabled by using third party JavaScript libraries.\nIn this example we will be using KaTeX\nCreate a partial under /layouts/partials/math.html Within this partial reference the Auto-render Extension or host these scripts locally. Include the partial in your templates like so: 1 2 3 {{ if or .Params.math .Site.Params.math }} {{ partial \u0026#34;math.html\u0026#34; . }} {{ end }} To enable KaTeX globally set the parameter math to true in a project\u0026rsquo;s configuration To enable KaTeX on a per page basis include the parameter math: true in content files Note: Use the online reference of Supported TeX Functions\nExamples\rInline math: $\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887…$\n$$\r\\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$","date":"0001-01-01T00:00:00Z","permalink":"http://localhost:1313/post/math-typesetting/","title":"Math Typesetting"},{"content":"正文测试\r而如此， 这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 带着这些问题，我们来审视一下学生会退会。 我认为， 我认为， 在这种困难的抉择下，本人思来想去，寝食难安。 问题的关键究竟为何？ 每个人都不得不面对这些问题。 在面对这种问题时， 要想清楚，学生会退会，到底是一种怎么样的存在。 我认为， 既然如此， 每个人都不得不面对这些问题。 在面对这种问题时， 那么， 我认为， 学生会退会因何而发生。\n引用\r思念是最暖的忧伤像一双翅膀\n让我停不了飞不远在过往游荡\n不告而别的你 就算为了我着想\n这么沉痛的呵护 我怎么能翱翔\n最暖的憂傷 - 田馥甄\n图片\r1 2 3 ![Photo by Florian Klauer on Unsplash](florian-klauer-nptLmg6jqDo-unsplash.jpg) ![Photo by Luca Bravo on Unsplash](luca-bravo-alS7ewQ41M8-unsplash.jpg) ![Photo by Helena Hertz on Unsplash](helena-hertz-wWZzXlDpMog-unsplash.jpg) ![Photo by Hudai Gayiran on Unsplash](hudai-gayiran-3Od_VKcDEAA-unsplash.jpg) 相册语法来自 Typlog\n","date":"0001-01-01T00:00:00Z","image":"http://localhost:1313/post/%E4%B8%AD%E6%96%87%E6%B5%8B%E8%AF%95/helena-hertz-wWZzXlDpMog-unsplash_hu_2307260c751d0e0b.jpg","permalink":"http://localhost:1313/post/%E4%B8%AD%E6%96%87%E6%B5%8B%E8%AF%95/","title":"中文测试"},{"content":"正文测试\raadda\naaadddada\n","date":"0001-01-01T00:00:00Z","image":"http://localhost:1313/helena-hertz-wWZzXlDpMog-unsplash.jpg","permalink":"http://localhost:1313/post/adada/","title":"中文测试2"}]