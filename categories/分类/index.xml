<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>分类 on 潘旺基の博客</title>
        <link>http://localhost:1313/categories/%E5%88%86%E7%B1%BB/</link>
        <description>Recent content in 分类 on 潘旺基の博客</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>潘旺基的博客</copyright>
        <lastBuildDate>Fri, 21 Mar 2025 23:18:58 +0800</lastBuildDate><atom:link href="http://localhost:1313/categories/%E5%88%86%E7%B1%BB/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>AI与.NET技术实操系列（六）：基于图像分类模型对图像进行分类</title>
        <link>http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E5%85%AD%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E5%AF%B9%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/</link>
        <pubDate>Fri, 21 Mar 2025 23:18:58 +0800</pubDate>
        
        <guid>http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E5%85%AD%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E5%AF%B9%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/</guid>
        <description>&lt;img src="http://localhost:1313/img/avatar.jpg" alt="Featured image of post AI与.NET技术实操系列（六）：基于图像分类模型对图像进行分类" /&gt;&lt;h2 id=&#34;引言&#34;&gt;引言
&lt;/h2&gt;&lt;p&gt;人工智能（AI）技术的迅猛发展推动了各行各业的数字化转型。图像分类，作为计算机视觉领域的核心技术之一，能够让机器自动识别图像中的物体、场景或特征，已广泛应用于医疗诊断、安防监控、自动驾驶和电子商务等领域。&lt;/p&gt;
&lt;p&gt;与此同时，.NET 平台凭借其高效性、跨平台能力和强大的 C# 编程语言支持，成为开发者构建企业级应用的首选技术栈。将 AI 图像分类模型与 .NET 技术结合，不仅能充分发挥两者的优势，还能为开发者提供一种高效、直观的实现方式。&lt;/p&gt;
&lt;p&gt;本文将详细介绍如何在 .NET 环境下使用 C# 部署和调用 AI 图像分类模型。我们将从环境搭建、模型选择，到模型调用，再到实际应用场景，逐步展开讲解，并提供丰富的代码示例和实践指导，帮助开发者快速上手并应用到实际项目中。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;准备工作&#34;&gt;准备工作
&lt;/h2&gt;&lt;p&gt;在开始实现图像分类之前，我们需要准备必要的开发环境和工具。以下是所需的软件和库：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Visual Studio&lt;/strong&gt;：Visual Studio 2022。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;.NET SDK&lt;/strong&gt;：安装 .NET 6.0 或更高版本，确保支持最新的功能和性能优化。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ML.NET&lt;/strong&gt;：微软提供的开源机器学习框架，专为 .NET 开发者设计，支持模型训练和推理。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;模型文件&lt;/strong&gt;：我们将使用预训练的图像分类模型 tensorflow_inception_graph.pb。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;安装步骤&#34;&gt;安装步骤
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;创建项目并添加依赖&lt;/strong&gt;：在命令行中运行以下命令，创建一个控制台应用程序并安装必要的 NuGet 包：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;dotnet new console -n ImageClassificationDemocd ImageClassificationDemodotnet add package Microsoft.MLdotnet add package Microsoft.ML.ImageAnalyticsdotnet add package Microsoft.ML.TensorFlowdotnet add package SciSharp.TensorFlow.Redist
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;完成以上步骤后，你的环境就准备好了。接下来，我们将选择一个合适的图像分类模型。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;图像分类模型的选择&#34;&gt;图像分类模型的选择
&lt;/h2&gt;&lt;p&gt;图像分类模型是基于监督学习的神经网络，其目标是将输入图像分配到预定义的类别中。在选择模型时，我们需要考虑模型的性能、计算复杂度和适用场景。以下是几种常见的图像分类模型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;卷积神经网络（CNN）&lt;/strong&gt;：如 LeNet、AlexNet 和 VGGNet，适合基本的图像分类任务，但层数较深时可能面临梯度消失问题。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;残差网络（ResNet）&lt;/strong&gt;：通过引入残差连接（skip connections），解决了深层网络的训练难题，适用于高精度分类任务。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;EfficientNet&lt;/strong&gt;：通过平衡网络深度、宽度和分辨率，提供高效的性能，适合资源受限的场景。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;模型训练与导出&#34;&gt;模型训练与导出
&lt;/h3&gt;&lt;p&gt;考虑到时间和资源成本，我们将直接使用预训练的 &lt;strong&gt;tensorflow_inception_graph.pb&lt;/strong&gt; 模型。如果你有自定义需求，可以使用以下步骤训练并导出模型：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;数据准备&lt;/strong&gt;：收集并标注图像数据集，分为训练集和验证集。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;训练模型&lt;/strong&gt;：使用 TensorFlow 或 PyTorch 等框架训练模型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;导出模型&lt;/strong&gt;：利用框架提供的导出工具导出模型。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在本文中，我们选择 &lt;strong&gt;tensorflow_inception_graph.pb&lt;/strong&gt; 作为示例模型，这是一种由Google开发的高性能卷积神经网络（CNN）架构。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;❝&lt;/p&gt;
&lt;p&gt;该模块通过并行使用不同大小的卷积核（如1x1、3x3、5x5）和池化层，提取图像的多尺度特征。这种设计提高了模型在图像分类任务中的表现，同时保持了计算效率。支持 1000 个类别的分类，且可以轻松集成到 .NET 中。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;大家可以直接点击 &lt;a class=&#34;link&#34; href=&#34;https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;tensorflow_inception_graph.pb&lt;/a&gt; 下载（文章最后也有下载方式）预训练的模型文件和分类文件，并将其放入项目目录中。&lt;/p&gt;
&lt;p&gt;也可以到&lt;a class=&#34;link&#34; href=&#34;https://github.com/martinwicke/tensorflow-tutorial/blob/master/tensorflow_inception_graph.pb&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;github&lt;/a&gt;上下载（文章最后也有下载方式），里面的内容相对来说也更丰富些。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E5%85%AD%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E5%AF%B9%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/images/aade711f-6e0a-4752-9a81-7a9740b59eeb.png&#34;
	width=&#34;1476&#34;
	height=&#34;760&#34;
	srcset=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E5%85%AD%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E5%AF%B9%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/images/aade711f-6e0a-4752-9a81-7a9740b59eeb_hu_eea9652c337211f8.png 480w, http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E5%85%AD%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E5%AF%B9%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/images/aade711f-6e0a-4752-9a81-7a9740b59eeb_hu_312c83f0b023635.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;194&#34;
		data-flex-basis=&#34;466px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;在-net-中调用模型&#34;&gt;在 .NET 中调用模型
&lt;/h2&gt;&lt;p&gt;现在，我们进入核心部分：在 .NET 中调用 tensorflow_inception_graph.pb。以下是逐步实现的过程。&lt;/p&gt;
&lt;h3 id=&#34;1-创建-net-项目&#34;&gt;1. 创建 .NET 项目
&lt;/h3&gt;&lt;p&gt;使用命令行创建一个控制台应用，项目基本结构如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ImageClassificationDemo/├── ImageClassificationDemo.csproj├── Program.cs├── assets/inputs/inception/tensorflow_inception_graph.pb├── assets/inputs/inception/imagenet_comp_graph_label_strings.txt
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;2-定义输入和输出数据结构&#34;&gt;2. 定义输入和输出数据结构
&lt;/h3&gt;&lt;p&gt;如果在运行的时候报错说找不到模型或者label文件，可以进行如下操作：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E5%85%AD%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E5%AF%B9%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/images/f01bfb24-2b46-4e58-adf4-ce2f1816844a.png&#34;
	width=&#34;443&#34;
	height=&#34;172&#34;
	srcset=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E5%85%AD%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E5%AF%B9%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/images/f01bfb24-2b46-4e58-adf4-ce2f1816844a_hu_850341e17e2e31c3.png 480w, http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E5%85%AD%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E5%AF%B9%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/images/f01bfb24-2b46-4e58-adf4-ce2f1816844a_hu_4f79bc0c459e86e5.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;257&#34;
		data-flex-basis=&#34;618px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;输入类中定义数据的结构如下，后续会使用 &lt;strong&gt;TextLoader&lt;/strong&gt; 加载数据时引用该类型。此处的类名为 &lt;strong&gt;ImageNetData&lt;/strong&gt;：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    public class ImageNetData    {        [LoadColumn(0)]        public string ImagePath;        [LoadColumn(1)]        public string Label;        public static IEnumerable&amp;lt;ImageNetData&amp;gt; ReadFromCsv(string file, string folder)        {            return File.ReadAllLines(file)             .Select(x =&amp;gt; x.Split(&amp;#39;\t&amp;#39;))             .Select(x =&amp;gt; new ImageNetData { ImagePath = Path.Combine(folder, x[0]), Label = x[1] } );        }    }    public class ImageNetDataProbability : ImageNetData    {        public string PredictedLabel;        public float Probability { get; set; }    }
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;❝&lt;/p&gt;
&lt;p&gt;需要强调的是，&lt;strong&gt;ImageNetData&lt;/strong&gt; 类中的标签在使用 TensorFlow 模型进行评分时并没有真正使用。而是在测试预测时使用它，这样就可以将每个样本数据的实际标签与 TensorFlow 模型提供的预测标签进行比较。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;输出类的结构如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;public class ImageNetPrediction{    [ColumnName(TFModelScorer.InceptionSettings.outputTensorName)]    public float[] PredictedLabels;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Inception 模型还需要几个传入的默认参数：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-gdscript3&#34; data-lang=&#34;gdscript3&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ImageNetSettings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;ne&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imageHeight&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;224&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;ne&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imageWidth&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;224&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;ne&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;117&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;ne&#34;&gt;bool&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;channelsLast&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;}&lt;/span&gt;      
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;3-定义-estimator-管道&#34;&gt;3. 定义 estimator 管道
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;❝&lt;/p&gt;
&lt;p&gt;在处理深度神经网络时，必须使图像适应网络期望的格式。这就是图像被调整大小然后转换的原因（主要是像素值在所有R，G，B通道上被归一化）。&lt;/p&gt;&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-gdscript3&#34; data-lang=&#34;gdscript3&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pipeline&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mlContext&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;LoadImages&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;outputColumnName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;input&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imageFolder&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imagesFolder&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;inputColumnName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nameof&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ImageNetData&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ImagePath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mlContext&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ResizeImages&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;outputColumnName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;input&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imageWidth&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ImageNetSettings&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;imageWidth&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imageHeight&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ImageNetSettings&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;imageHeight&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;inputColumnName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;input&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mlContext&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ExtractPixels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;outputColumnName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;input&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;interleavePixelColors&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ImageNetSettings&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;channelsLast&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;offsetImage&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ImageNetSettings&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mlContext&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;LoadTensorFlowModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;modelLocation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;        &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ScoreTensorFlowModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;outputColumnNames&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;softmax2&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;},&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;inputColumnNames&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;input&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;            &lt;span class=&#34;n&#34;&gt;addBatchDimensionInput&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;));&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;运行代码后，模型将被成功加载到内存中，接下来我们可以调用它进行图像分类。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;❝&lt;/p&gt;
&lt;p&gt;通常情况下，这里经常报的错就是输入/输出节点的名称不正确，你可以通过 Netron (&lt;a class=&#34;link&#34; href=&#34;https://netron.app/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://netron.app/&lt;/a&gt;)工具查看输入/输出节点的名称。&lt;/p&gt;
&lt;p&gt;因为这两个节点的名称后面会在 estimator 的定义中使用：在 inception 网络的情况下，输入张量命名为 &amp;lsquo;input&amp;rsquo;，输出命名为 &amp;lsquo;softmax2&amp;rsquo;。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;下图是通过 &lt;strong&gt;Netron&lt;/strong&gt; 读取的 &lt;strong&gt;tensorflow_inception_graph.pb&lt;/strong&gt; 模型分析图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E5%85%AD%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E5%AF%B9%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/images/0819caf8-2df3-493c-9c46-1333c0526707.png&#34;
	width=&#34;1824&#34;
	height=&#34;762&#34;
	srcset=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E5%85%AD%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E5%AF%B9%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/images/0819caf8-2df3-493c-9c46-1333c0526707_hu_60a9958a87910330.png 480w, http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E5%85%AD%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E5%AF%B9%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/images/0819caf8-2df3-493c-9c46-1333c0526707_hu_c06270086cee56cd.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;输入张量名&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;239&#34;
		data-flex-basis=&#34;574px&#34;
	
&gt;输入张量名
&lt;img src=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E5%85%AD%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E5%AF%B9%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/images/80ccc9a1-0b6c-41d5-ae48-3ef6cd0f7dc6.png&#34;
	width=&#34;1862&#34;
	height=&#34;866&#34;
	srcset=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E5%85%AD%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E5%AF%B9%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/images/80ccc9a1-0b6c-41d5-ae48-3ef6cd0f7dc6_hu_5109ead618875c09.png 480w, http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E5%85%AD%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E5%AF%B9%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/images/80ccc9a1-0b6c-41d5-ae48-3ef6cd0f7dc6_hu_d2c4edcfda98871a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;输出张量名&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;215&#34;
		data-flex-basis=&#34;516px&#34;
	
&gt;输出张量名&lt;/p&gt;
&lt;h3 id=&#34;4-提取预测结果&#34;&gt;4. 提取预测结果
&lt;/h3&gt;&lt;p&gt;填充 &lt;strong&gt;estimator&lt;/strong&gt; 管道&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-gdscript3&#34; data-lang=&#34;gdscript3&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;ITransformer&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pipeline&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;predictionEngine&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mlContext&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CreatePredictionEngine&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ImageNetData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ImageNetPrediction&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;当获得预测结果后，我们会在属性中得到一个浮点数数组。数组中的每个位置都会分配到一个标签。&lt;/p&gt;
&lt;p&gt;例如，如果模型有5个不同的标签，则数组将为length = 5。数组中的每个位置都表示标签在该位置的概率；所有数组值（概率）的和等于1。&lt;/p&gt;
&lt;p&gt;然后，您需要选择最大的值（概率），并检查配给了该位置的那个以填充 estimator 管道标签。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;调用模型进行图像分类&#34;&gt;调用模型进行图像分类
&lt;/h2&gt;&lt;p&gt;接下来我们需要编写代码来加载图像、进行预测并解析结果。&lt;/p&gt;
&lt;h3 id=&#34;1-准备素材与分类文件&#34;&gt;1. 准备素材与分类文件
&lt;/h3&gt;&lt;p&gt;定义图像文件夹目录和图像分类目录。以下代码加载并预处理图像：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;string assetsRelativePath = @&amp;#34;../../../assets&amp;#34;;string assetsPath = GetAbsolutePath(assetsRelativePath);string tagsTsv = Path.Combine(assetsPath, &amp;#34;inputs&amp;#34;, &amp;#34;images&amp;#34;, &amp;#34;tags.tsv&amp;#34;);string imagesFolder = Path.Combine(assetsPath, &amp;#34;inputs&amp;#34;, &amp;#34;images&amp;#34;);string inceptionPb = Path.Combine(assetsPath, &amp;#34;inputs&amp;#34;, &amp;#34;inception&amp;#34;, &amp;#34;tensorflow_inception_graph.pb&amp;#34;);string labelsTxt = Path.Combine(assetsPath, &amp;#34;inputs&amp;#34;, &amp;#34;inception&amp;#34;, &amp;#34;imagenet_comp_graph_label_strings.txt&amp;#34;);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;2-加载模型&#34;&gt;2. 加载模型
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-gdscript3&#34; data-lang=&#34;gdscript3&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;private&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PredictionEngine&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ImageNetData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ImageNetPrediction&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;LoadModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dataLocation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imagesFolder&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;modelLocation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;ConsoleWriteHeader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Read model&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;Console&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;WriteLine&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Model location: {modelLocation}&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;Console&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;WriteLine&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Images folder: {imagesFolder}&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;Console&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;WriteLine&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Training file: {dataLocation}&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;Console&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;WriteLine&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Default parameters: image size=({ImageNetSettings.imageWidth},{ImageNetSettings.imageHeight}), image mean: {ImageNetSettings.mean}&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mlContext&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;LoadFromTextFile&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ImageNetData&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dataLocation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;hasHeader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pipeline&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mlContext&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;LoadImages&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;outputColumnName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;input&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imageFolder&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imagesFolder&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;inputColumnName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nameof&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ImageNetData&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ImagePath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;                    &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mlContext&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ResizeImages&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;outputColumnName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;input&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imageWidth&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ImageNetSettings&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;imageWidth&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imageHeight&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ImageNetSettings&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;imageHeight&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;inputColumnName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;input&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;                    &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mlContext&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Transforms&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ExtractPixels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;outputColumnName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;input&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;interleavePixelColors&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ImageNetSettings&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;channelsLast&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;offsetImage&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ImageNetSettings&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;                    &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mlContext&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;LoadTensorFlowModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;modelLocation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;                    &lt;span class=&#34;n&#34;&gt;ScoreTensorFlowModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;outputColumnNames&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;softmax2&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;                                        &lt;span class=&#34;n&#34;&gt;inputColumnNames&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;input&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;},&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;addBatchDimensionInput&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;));&lt;/span&gt;                    &lt;span class=&#34;n&#34;&gt;ITransformer&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pipeline&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;predictionEngine&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mlContext&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CreatePredictionEngine&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ImageNetData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ImageNetPrediction&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;predictionEngine&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;3-解析输出结果&#34;&gt;3. 解析输出结果
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-gdscript3&#34; data-lang=&#34;gdscript3&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;protected&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;IEnumerable&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ImageNetData&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PredictDataUsingModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;testLocation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;                                                           &lt;span class=&#34;n&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imagesFolder&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;                                                           &lt;span class=&#34;n&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labelsLocation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;                                                           &lt;span class=&#34;n&#34;&gt;PredictionEngine&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ImageNetData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ImageNetPrediction&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;ConsoleWriteHeader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Classify images&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;Console&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;WriteLine&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Images folder: {imagesFolder}&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;Console&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;WriteLine&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Training file: {testLocation}&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;Console&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;WriteLine&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Labels file: {labelsLocation}&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ReadLabels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;labelsLocation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;testData&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ImageNetData&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ReadFromCsv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;testLocation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imagesFolder&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;foreach&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sample&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;testData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;        &lt;span class=&#34;k&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;probs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Predict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;PredictedLabels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;        &lt;span class=&#34;k&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imageData&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ImageNetDataProbability&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;        &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;            &lt;span class=&#34;n&#34;&gt;ImagePath&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ImagePath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;            &lt;span class=&#34;ne&#34;&gt;Label&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Label&lt;/span&gt;        &lt;span class=&#34;p&#34;&gt;};&lt;/span&gt;        &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;imageData&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;PredictedLabel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imageData&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Probability&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GetBestLabel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;probs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;        &lt;span class=&#34;n&#34;&gt;imageData&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ConsoleWrite&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;        &lt;span class=&#34;nb&#34;&gt;yield&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;imageData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;    &lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;在 &lt;code&gt;Main&lt;/code&gt; 方法中调用，完整代码如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;static void Main(string[] args){    string assetsRelativePath = @&amp;#34;../../../assets&amp;#34;;    string assetsPath = GetAbsolutePath(assetsRelativePath);    string tagsTsv = Path.Combine(assetsPath, &amp;#34;inputs&amp;#34;, &amp;#34;images&amp;#34;, &amp;#34;tags.tsv&amp;#34;);    string imagesFolder = Path.Combine(assetsPath, &amp;#34;inputs&amp;#34;, &amp;#34;images&amp;#34;);    string inceptionPb = Path.Combine(assetsPath, &amp;#34;inputs&amp;#34;, &amp;#34;inception&amp;#34;, &amp;#34;tensorflow_inception_graph.pb&amp;#34;);    string labelsTxt = Path.Combine(assetsPath, &amp;#34;inputs&amp;#34;, &amp;#34;inception&amp;#34;, &amp;#34;imagenet_comp_graph_label_strings.txt&amp;#34;);    try    {        TFModelScorer modelScorer = new TFModelScorer(tagsTsv, imagesFolder, inceptionPb, labelsTxt);        modelScorer.Score();    }    catch (Exception ex)    {        ConsoleHelpers.ConsoleWriteException(ex.ToString());    }    ConsoleHelpers.ConsolePressAnyKey();}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;运行程序后，你将看到类似以下的输出：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E5%85%AD%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E5%AF%B9%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/images/1fd8ceee-fcca-492b-8fe3-1b0dc0280aee.png&#34;
	width=&#34;723&#34;
	height=&#34;385&#34;
	srcset=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E5%85%AD%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E5%AF%B9%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/images/1fd8ceee-fcca-492b-8fe3-1b0dc0280aee_hu_2f54c8a0f10997f9.png 480w, http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E5%85%AD%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E5%AF%B9%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/images/1fd8ceee-fcca-492b-8fe3-1b0dc0280aee_hu_3563f11d615418b6.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;187&#34;
		data-flex-basis=&#34;450px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;其他实现方式&#34;&gt;其他实现方式
&lt;/h2&gt;&lt;p&gt;在实际应用中，我们也可以使用ONNX模型，此处不做额外叙述。由于模型的性能和效率至关重要，只是提供一些优化建议：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;模型量化&lt;/strong&gt;：使用 ONNX Runtime 的量化工具，将模型从浮点数（FP32）转换为整数（INT8），减少模型大小和推理时间。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;硬件加速&lt;/strong&gt;：结合 ONNX Runtime 的 GPU 支持，利用 CUDA 或 DirectML 加速推理。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;批处理&lt;/strong&gt;：如果需要处理多张图像，可以将输入组织为批次（batch），提高吞吐量。例如：&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-gdscript3&#34; data-lang=&#34;gdscript3&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;inputs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;List&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ImageInput&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;input1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;input2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;input3&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;};&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;batchPrediction&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mlContext&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;LoadFromEnumerable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;inputs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;predictions&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Transform&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;batchPrediction&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;缓存机制&lt;/strong&gt;：对于频繁使用的模型，保持预测引擎的单例实例，避免重复加载。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;通过这些优化，模型可以在 .NET 环境中实现更高的性能，满足实时应用的需求。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;实际应用场景&#34;&gt;实际应用场景
&lt;/h2&gt;&lt;p&gt;图像分类模型在 .NET 应用中有广泛的用途，以下是几个典型场景：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;医疗影像分析&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在医疗系统中，部署图像分类模型可以辅助医生识别 X 光片或 MRI 图像中的异常。例如，检测肺部结节或肿瘤。
2. &lt;strong&gt;智能安防&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在监控系统中，模型可以实时识别可疑物体或行为，如检测闯入者或遗留物品。
3. &lt;strong&gt;电子商务&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在商品管理系统中，自动分类上传的商品图像，提升搜索和推荐的准确性。&lt;/p&gt;
&lt;h3 id=&#34;挑战与解决方案&#34;&gt;挑战与解决方案
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数据隐私&lt;/strong&gt;：通过加密传输和本地推理保护用户数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;模型更新&lt;/strong&gt;：定期从云端下载新模型，并使用版本控制管理。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;计算资源&lt;/strong&gt;：在资源受限的设备上，使用轻量化模型（如 MobileNet）。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;结论&#34;&gt;结论
&lt;/h2&gt;&lt;p&gt;本文详细介绍了如何在 .NET 环境下使用 C# 部署和调用 AI 图像分类模型。从环境搭建到模型选择、部署与调用，再到性能优化和应用场景，我们提供了一套完整的实践指南。通过 ML.NET 和预测模式的支持，开发者可以轻松地将强大的 AI 能力集成到 .NET 应用中。&lt;/p&gt;
&lt;p&gt;随着 AI 技术的不断进步和 .NET 平台的持续发展，二者的结合将为开发者带来更多可能性。无论是构建智能桌面应用、Web 服务还是跨平台解决方案，图像分类模型都能为项目增添创新价值。希望本文能为你的 AI 之旅提供启发和帮助！&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;素材下载地址：&lt;/strong&gt; &lt;a class=&#34;link&#34; href=&#34;https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Netron工具地址：&lt;/strong&gt; &lt;a class=&#34;link&#34; href=&#34;https://netron.app/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://netron.app/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;224x224图像素材：&lt;/strong&gt; &lt;a class=&#34;link&#34; href=&#34;https://www.kaggle.com/datasets/abhinavnayak/catsvdogs-transformed/data&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.kaggle.com/datasets/abhinavnayak/catsvdogs-transformed/data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;tensorflow教程及模型文件和label文件：&lt;/strong&gt; &lt;a class=&#34;link&#34; href=&#34;https://github.com/martinwicke/tensorflow-tutorial&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/martinwicke/tensorflow-tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Image Classification - Scoring sample：&lt;/strong&gt; &lt;a class=&#34;link&#34; href=&#34;https://github.com/dotnet/machinelearning-samples/blob/main/samples/csharp/getting-started/DeepLearning&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/dotnet/machinelearning-samples/blob/main/samples/csharp/getting-started/DeepLearning&lt;/a&gt;_ImageClassification_TensorFlow/README.md&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ML.NET 官方文档：&lt;/strong&gt; &lt;a class=&#34;link&#34; href=&#34;https://dotnet.microsoft.com/apps/machinelearning-ai/ml-dotnet&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://dotnet.microsoft.com/apps/machinelearning-ai/ml-dotnet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ONNX Model Zoo：&lt;/strong&gt; &lt;a class=&#34;link&#34; href=&#34;https://github.com/onnx/models&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/onnx/models&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>0314 Aas</title>
        <link>http://localhost:1313/post/%E8%BF%99%E6%98%AF%E6%96%87%E7%AB%A0%E5%95%8A%E5%95%8A%E5%95%8A/%E6%96%87%E7%AB%A0/</link>
        <pubDate>Fri, 14 Mar 2025 23:16:45 +0800</pubDate>
        
        <guid>http://localhost:1313/post/%E8%BF%99%E6%98%AF%E6%96%87%E7%AB%A0%E5%95%8A%E5%95%8A%E5%95%8A/%E6%96%87%E7%AB%A0/</guid>
        <description>&lt;img src="http://localhost:1313/img/avatar.jpg" alt="Featured image of post 0314 Aas" /&gt;&lt;p&gt;aa这是文章啊啊啊啊啊 啊&lt;/p&gt;
</description>
        </item>
        <item>
        <title>AI与.NET技术实操系列（七）：使用Emgu CV进行计算机视觉操作</title>
        <link>http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%B8%83%E4%BD%BF%E7%94%A8emgu-cv%E8%BF%9B%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%93%8D%E4%BD%9C/</link>
        <pubDate>Fri, 14 Mar 2025 23:16:45 +0800</pubDate>
        
        <guid>http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%B8%83%E4%BD%BF%E7%94%A8emgu-cv%E8%BF%9B%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%93%8D%E4%BD%9C/</guid>
        <description>&lt;img src="http://localhost:1313/img/avatar.jpg" alt="Featured image of post AI与.NET技术实操系列（七）：使用Emgu CV进行计算机视觉操作" /&gt;&lt;h2 id=&#34;引言&#34;&gt;引言
&lt;/h2&gt;&lt;p&gt;计算机视觉（Computer Vision, CV）是人工智能领域中最为引人注目的分支之一。从自动驾驶汽车到医疗影像分析，从智能安防系统到虚拟现实体验，计算机视觉的应用无处不在，深刻地改变着我们的生活和工作方式。&lt;/p&gt;
&lt;p&gt;对于.NET开发者而言，掌握计算机视觉技术不仅意味着能够开发出更智能、更具创新性的应用程序，更是在竞争激烈的市场中保持领先的关键。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;❝&lt;/p&gt;
&lt;p&gt;Emgu CV作为OpenCV的.NET包装器，为开发者提供了一个强大的工具，使他们能够在熟悉的.NET环境中轻松应用计算机视觉技术，无需深入学习其他编程语言或平台。&lt;strong&gt;其实怎么用这个库倒不是很重要，关键是要转变观念，提升自己对技术的理解力。&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;本文将通过一个具体的实践任务——使用Emgu CV进行人脸检测，展示如何在.NET中应用计算机视觉技术。这个任务贴近实际业务需求，能够帮助读者深入理解Emgu CV的使用方法和计算机视觉的基本原理。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;emgu-cv简介&#34;&gt;Emgu CV简介
&lt;/h2&gt;&lt;p&gt;在深入探讨Emgu CV之前，我们先来初步的了解一下它是什么以及它在计算机视觉应用开发中的作用。&lt;/p&gt;
&lt;h3 id=&#34;什么是emgu-cv&#34;&gt;什么是Emgu CV？
&lt;/h3&gt;&lt;p&gt;Emgu CV是一个跨平台的.NET包装器，专门为OpenCV库设计，旨在使.NET开发者能够轻松地使用OpenCV的功能。&lt;/p&gt;
&lt;p&gt;OpenCV（Open Source Computer Vision Library）是一个开源的计算机视觉和机器学习软件库，包含了大量的图像处理、计算机视觉和机器学习算法，被广泛应用于学术研究和工业应用中。&lt;/p&gt;
&lt;p&gt;Emgu CV的出现极大地降低了计算机视觉技术的入门门槛。它不仅支持图像处理、特征检测、对象识别等多种功能，还提供了丰富的API和文档，使得开发者能够快速上手并实现复杂的视觉任务。无论是构建人脸识别系统、实时视频分析工具，还是自动化质量检测系统，Emgu CV都能为开发者提供强有力的支持。&lt;/p&gt;
&lt;p&gt;Emgu CV通过提供C#、VB.NET等.NET平台的接口，允许开发者在.NET环境中调用OpenCV的功能。它支持Windows、Linux、macOS等多个平台，并与.NET Framework、.NET Core和Xamarin等.NET技术栈兼容。Emgu CV不仅封装了OpenCV的核心功能，还提供了一些额外的工具和扩展，如GPU加速、深度学习模块等，使开发者能够构建高性能的计算机视觉应用。&lt;/p&gt;
&lt;h3 id=&#34;emgu-cv的优势&#34;&gt;Emgu CV的优势
&lt;/h3&gt;&lt;p&gt;与直接使用OpenCV的C++接口相比，Emgu CV具有以下显著优势：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;易于集成&lt;/strong&gt;：开发者可以在Visual Studio等IDE中直接使用NuGet包管理器安装Emgu CV，无需手动编译和配置OpenCV库。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;丰富的文档和示例&lt;/strong&gt;：Emgu CV提供了详细的文档和丰富的代码示例，帮助开发者快速上手。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;跨平台支持&lt;/strong&gt;：Emgu CV支持多个操作系统和.NET平台，使开发者能够构建跨平台的计算机视觉应用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;社区支持&lt;/strong&gt;：Emgu CV拥有活跃的社区，开发者可以在论坛和GitHub上获取帮助和分享经验。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这些优势使Emgu CV成为.NET开发者进行计算机视觉开发的首选工具。无论你是初学者还是经验丰富的开发者，Emgu CV都能帮助你快速实现创意并构建智能应用。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;安装和配置emgu-cv&#34;&gt;安装和配置Emgu CV
&lt;/h2&gt;&lt;p&gt;在开始使用Emgu CV之前，我们需要安装Emgu CV的NuGet包并配置开发环境。以下是详细的安装和配置步骤。&lt;/p&gt;
&lt;h3 id=&#34;安装emgu-cv&#34;&gt;安装Emgu CV
&lt;/h3&gt;&lt;p&gt;Emgu CV可以通过NuGet包管理器安装。以下是安装Emgu CV核心包的步骤：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;dotnet add package Emgu.CVdotnet add package Emgu.CV.runtime.windows
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;配置开发环境&#34;&gt;配置开发环境
&lt;/h3&gt;&lt;p&gt;Emgu CV的使用需要确保OpenCV的DLL文件在运行时可用。通常，安装“Emgu.CV.runtime.windows”包后，DLL文件会自动复制到输出目录。如果在使用过程中遇到DLL缺失的错误，可以手动将DLL文件复制到项目的输出目录中。&lt;/p&gt;
&lt;p&gt;此外，Emgu CV支持GPU加速，如果你希望使用GPU功能，需要安装相应的CUDA工具包并配置环境变量。详细的配置步骤可以参考Emgu CV的官方文档。&lt;/p&gt;
&lt;h3 id=&#34;注意事项&#34;&gt;注意事项
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;版本兼容性&lt;/strong&gt;：Emgu CV的版本与OpenCV的版本相对应，确保你使用的Emgu CV版本与你的项目需求兼容。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;平台支持&lt;/strong&gt;：根据你的目标平台（如Windows、Linux），选择合适的运行时包。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;许可证&lt;/strong&gt;：Emgu CV提供商业和开源两种许可证，开发者需要根据项目需求选择合适的许可证。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;完成这些步骤后，你的开发环境就已准备好，可以开始使用Emgu CV进行计算机视觉任务了。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;图像处理基础&#34;&gt;图像处理基础
&lt;/h2&gt;&lt;p&gt;在掌握了Emgu CV的安装和配置后，我们将学习图像处理的基础知识，包括图像的加载、显示、保存以及基本的像素操作。这些基础操作是进行更复杂计算机视觉任务的前提。&lt;/p&gt;
&lt;h3 id=&#34;图像加载与显示&#34;&gt;图像加载与显示
&lt;/h3&gt;&lt;p&gt;Emgu CV提供了&lt;code&gt;CvInvoke.Imread&lt;/code&gt;方法来加载图像文件，并使用&lt;code&gt;CvInvoke.Imshow&lt;/code&gt;方法显示图像。以下是一个简单的图像加载和显示示例：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;using Emgu.CV;using Emgu.CV.CvEnum;// 加载图像using Emgu.CV.CvEnum;using Emgu.CV;Mat image = CvInvoke.Imread(&amp;#34;input.png&amp;#34;, ImreadModes.Color);if (image.IsEmpty){    Console.WriteLine(&amp;#34;无法加载图像&amp;#34;);    return;}Console.WriteLine(&amp;#34;加载图像完成&amp;#34;);// 显示图像CvInvoke.Imshow(&amp;#34;Image&amp;#34;, image);CvInvoke.WaitKey(0);CvInvoke.DestroyAllWindows();
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%B8%83%E4%BD%BF%E7%94%A8emgu-cv%E8%BF%9B%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%93%8D%E4%BD%9C/images/0ad7220d-8249-4cda-82dd-fe69b476ac45.jpg&#34;
	width=&#34;2375&#34;
	height=&#34;1084&#34;
	srcset=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%B8%83%E4%BD%BF%E7%94%A8emgu-cv%E8%BF%9B%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%93%8D%E4%BD%9C/images/0ad7220d-8249-4cda-82dd-fe69b476ac45_hu_7ddadb14151a1287.jpg 480w, http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%B8%83%E4%BD%BF%E7%94%A8emgu-cv%E8%BF%9B%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%93%8D%E4%BD%9C/images/0ad7220d-8249-4cda-82dd-fe69b476ac45_hu_504f734471938278.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;219&#34;
		data-flex-basis=&#34;525px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;在这个示例中，我们加载了一个彩色图像并在窗口中显示。&lt;code&gt;ImreadModes.Color&lt;/code&gt;指定加载彩色图像，你也可以使用&lt;code&gt;ImreadModes.Grayscale&lt;/code&gt;加载灰度图像。&lt;/p&gt;
&lt;h3 id=&#34;图像保存&#34;&gt;图像保存
&lt;/h3&gt;&lt;p&gt;使用&lt;code&gt;CvInvoke.Imwrite&lt;/code&gt;方法可以将图像保存到文件：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;CvInvoke.Imwrite(&amp;#34;output.jpg&amp;#34;, image);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;访问和修改像素&#34;&gt;访问和修改像素
&lt;/h3&gt;&lt;p&gt;Emgu CV允许开发者直接访问和修改图像的像素值。以下是如何访问和修改像素的示例：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;using Emgu.CV;using Emgu.CV.Structure;using System.Drawing;string imagePath = &amp;#34;input.png&amp;#34;;Mat image = CvInvoke.Imread(imagePath);if (image.IsEmpty){    Console.WriteLine(&amp;#34;无法加载图像，请检查文件路径是否正确。&amp;#34;);    return;}// 定义一个100x100的区域，从坐标(50,50)开始Rectangle roi = new Rectangle(50, 50, 100, 100);// 检查ROI是否超出图像边界if (roi.X + roi.Width &amp;gt; image.Width || roi.Y + roi.Height &amp;gt; image.Height){    Console.WriteLine(&amp;#34;指定的区域超出了图像边界，请调整ROI参数。&amp;#34;);    return;}// 获取指定区域的引用Mat region = new Mat(image, roi);// 将该区域设置为红色region.SetTo(new Bgr(0, 0, 255).MCvScalar);// 显示修改后的图像CvInvoke.Imshow(&amp;#34;Modified Image&amp;#34;, image);CvInvoke.WaitKey();
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;运行这段代码后，你会看到指定的图片被加载，并且从(50,50)到(149,149)的100x100区域被修改为红色。通过直接操作像素，开发者可以实现各种图像处理效果，如滤波、边缘检测等。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%B8%83%E4%BD%BF%E7%94%A8emgu-cv%E8%BF%9B%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%93%8D%E4%BD%9C/images/16e4a31e-4b07-4f61-b801-e07e46ce7d0f.jpg&#34;
	width=&#34;2085&#34;
	height=&#34;1067&#34;
	srcset=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%B8%83%E4%BD%BF%E7%94%A8emgu-cv%E8%BF%9B%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%93%8D%E4%BD%9C/images/16e4a31e-4b07-4f61-b801-e07e46ce7d0f_hu_a7793c2f492e62cf.jpg 480w, http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%B8%83%E4%BD%BF%E7%94%A8emgu-cv%E8%BF%9B%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%93%8D%E4%BD%9C/images/16e4a31e-4b07-4f61-b801-e07e46ce7d0f_hu_4da8511806c02cd8.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;195&#34;
		data-flex-basis=&#34;468px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;图像数据表示&#34;&gt;图像数据表示
&lt;/h3&gt;&lt;p&gt;在Emgu CV中，图像通常使用&lt;code&gt;Mat&lt;/code&gt;类表示。&lt;code&gt;Mat&lt;/code&gt;是一个多维密集数组，可以存储图像数据。开发者可以通过&lt;code&gt;Mat&lt;/code&gt;的属性和方法访问图像的尺寸、通道数、数据类型等信息。&lt;/p&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Console.WriteLine($&amp;#34;图像尺寸: {image.Width}x{image.Height}&amp;#34;);Console.WriteLine($&amp;#34;通道数: {image.NumberOfChannels}&amp;#34;);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;理解图像数据的表示方式对于进行高级图像处理和计算机视觉任务至关重要。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;对象检测实践&#34;&gt;对象检测实践
&lt;/h2&gt;&lt;p&gt;在掌握了图像处理的基础后，我们将通过一个具体的对象检测任务——人脸检测，展示如何使用Emgu CV实现计算机视觉应用。人脸检测是计算机视觉中最常见的应用之一，广泛应用于安防监控、身份验证、社交媒体等场景。&lt;/p&gt;
&lt;h3 id=&#34;使用haar级联分类器进行人脸检测&#34;&gt;使用Haar级联分类器进行人脸检测
&lt;/h3&gt;&lt;p&gt;Emgu CV提供了Haar级联分类器（Haar Cascade Classifier）的人脸检测功能。Haar级联分类器是一种基于机器学习的对象检测方法，通过训练大量正负样本学习对象的特征。&lt;/p&gt;
&lt;h4 id=&#34;准备工作&#34;&gt;准备工作
&lt;/h4&gt;&lt;p&gt;首先，我们需要一个Haar级联分类器的XML文件。Emgu CV提供了一些预训练的分类器，你可以从OpenCV的GitHub仓库下载，例如&lt;code&gt;haarcascade_frontalface_default.xml&lt;/code&gt;。&lt;/p&gt;
&lt;h4 id=&#34;实现人脸检测&#34;&gt;实现人脸检测
&lt;/h4&gt;&lt;p&gt;以下是使用Haar级联分类器进行人脸检测的代码示例：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;// 加载图像using Emgu.CV.CvEnum;using Emgu.CV.Structure;using Emgu.CV;using System.Drawing;// 加载图像Mat image = CvInvoke.Imread(&amp;#34;hejlsberg.png&amp;#34;);if (image.IsEmpty){    Console.WriteLine(&amp;#34;无法加载图像&amp;#34;);    return;}// 加载Haar级联分类器CascadeClassifier faceDetector = new CascadeClassifier(&amp;#34;haarcascade_frontalface_default.xml&amp;#34;);// 将图像转换为灰度图像Mat grayImage = new Mat();CvInvoke.CvtColor(image, grayImage, ColorConversion.Bgr2Gray);// 检测人脸Rectangle[] faces = faceDetector.DetectMultiScale(grayImage, 1.1, 10, Size.Empty, Size.Empty);// 在图像上绘制检测到的人脸foreach (Rectangle face in faces){    CvInvoke.Rectangle(image, face, new Bgr(Color.Red).MCvScalar, 2);}// 显示结果CvInvoke.Imshow(&amp;#34;Face Detection&amp;#34;, image);CvInvoke.WaitKey();CvInvoke.DestroyAllWindows();
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;代码解析&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;加载图像和分类器&lt;/strong&gt;：首先，加载输入图像和Haar级联分类器。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;灰度转换&lt;/strong&gt;：人脸检测通常在灰度图像上进行，因此将彩色图像转换为灰度图像。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;检测人脸&lt;/strong&gt;：使用&lt;code&gt;DetectMultiScale&lt;/code&gt;方法检测人脸，返回一个矩形数组，表示检测到的人脸位置。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;绘制矩形&lt;/strong&gt;：在原始图像上绘制红色矩形框，标记检测到的人脸。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;显示结果&lt;/strong&gt;：在窗口中显示带有标记的图像。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%B8%83%E4%BD%BF%E7%94%A8emgu-cv%E8%BF%9B%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%93%8D%E4%BD%9C/images/0308c8b3-bacb-4462-b1fa-13b86d656a77.png&#34;
	width=&#34;1932&#34;
	height=&#34;755&#34;
	srcset=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%B8%83%E4%BD%BF%E7%94%A8emgu-cv%E8%BF%9B%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%93%8D%E4%BD%9C/images/0308c8b3-bacb-4462-b1fa-13b86d656a77_hu_e4f84d94a8ff1205.png 480w, http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%B8%83%E4%BD%BF%E7%94%A8emgu-cv%E8%BF%9B%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%93%8D%E4%BD%9C/images/0308c8b3-bacb-4462-b1fa-13b86d656a77_hu_b91be0d6f8b1edb7.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;255&#34;
		data-flex-basis=&#34;614px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;通过这个示例，你可以看到Emgu CV在对象检测方面的强大功能。开发者可以根据需要调整检测参数，如&lt;code&gt;scaleFactor&lt;/code&gt;和&lt;code&gt;minNeighbors&lt;/code&gt;，以优化检测效果。&lt;/p&gt;
&lt;h3 id=&#34;高级对象检测&#34;&gt;高级对象检测
&lt;/h3&gt;&lt;p&gt;除了Haar级联分类器，Emgu CV还支持更高级的对象检测方法，如基于深度学习的YOLO（You Only Look Once）或SSD（Single Shot MultiBox Detector）。这些方法通常具有更高的准确性和鲁棒性，但需要更多的计算资源。开发者可以根据应用场景选择合适的检测算法。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;计算机视觉在实际应用中的意义和挑战&#34;&gt;计算机视觉在实际应用中的意义和挑战
&lt;/h2&gt;&lt;p&gt;计算机视觉技术在实际应用中具有巨大的潜力，但同时也面临着一些挑战。以下是一些需要关注的问题：&lt;/p&gt;
&lt;h3 id=&#34;意义&#34;&gt;意义
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;自动化和智能化&lt;/strong&gt;：计算机视觉可以自动化许多依赖视觉的任务，如质量检测、监控和导航。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;提升用户体验&lt;/strong&gt;：在社交媒体、游戏和虚拟现实中，计算机视觉技术可以提供更丰富的交互体验。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;医疗和科学应用&lt;/strong&gt;：在医疗影像分析、生物识别等领域，计算机视觉技术可以帮助医生和研究人员更准确地诊断和分析。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;挑战&#34;&gt;挑战
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;算法选择&lt;/strong&gt;：不同的应用场景需要不同的算法，开发者需要根据具体需求选择合适的算法和模型。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;性能优化&lt;/strong&gt;：实时计算机视觉应用对性能要求高，开发者需要优化算法和代码，以确保在有限的资源下实现高效处理。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;鲁棒性&lt;/strong&gt;：计算机视觉系统需要能够在各种光照、角度和遮挡条件下稳定工作，这对算法的鲁棒性提出了挑战。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;持续学习&lt;/strong&gt;：计算机视觉是一个快速发展的领域，新的算法和工具不断涌现。开发者需要保持学习的态度，不断更新知识，以应对新的挑战和机遇。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;尽管面临这些挑战，计算机视觉技术仍然为企业和组织带来了巨大的价值。通过自动化视觉任务、提高决策效率和创造新的商业机会，计算机视觉正在重塑各行各业。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;技术伦理&#34;&gt;技术伦理
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;❝&lt;/p&gt;
&lt;p&gt;我几乎会在我的每篇文章中都会加入这个讨论，因为技术的不可控性必然会带来各种各样的问题甚至是灾难性的问题。因此，我们必须要记住，技术进步应服务于社会福祉。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;计算机视觉技术的快速发展不仅带来了技术上的突破，更引发了对伦理和隐私问题的深刻思考。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;技术与伦理&lt;/strong&gt;：计算机视觉系统可能在无意中侵犯个人隐私或产生偏见性决策。开发者有责任确保技术的公平性和透明度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;隐私保护&lt;/strong&gt;：在收集和使用图像数据时，开发者需要遵守相关法律法规，保护用户的隐私权。数据匿名化、加密等技术可以帮助减少隐私风险。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;结语&#34;&gt;结语
&lt;/h2&gt;&lt;p&gt;本文通过介绍Emgu CV的基础知识、安装和配置、图像处理基础、对象检测实践以及实际应用中的意义和挑战，为.NET开发者提供了一个全面而深入的指南。Emgu CV作为OpenCV的.NET包装器，为开发者提供了一个强大的工具，使他们能够在.NET环境中轻松应用计算机视觉技术。&lt;/p&gt;
&lt;p&gt;希望本文能够激发你的兴趣，帮助你开启计算机视觉在.NET中的探索之旅，也希望因此你可以对.NET充满信息，未来的.NET一定会更好，当然在人工智能背景下，Python的重要性不言而喻，我们也要对Python有足够的了解，通过.NET + Python提升自己的竞争力。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>AI与.NET技术实操系列（五）：向量存储与相似性搜索在 .NET 中的实现</title>
        <link>http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/</link>
        <pubDate>Fri, 14 Mar 2025 23:16:45 +0800</pubDate>
        
        <guid>http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/</guid>
        <description>&lt;img src="http://localhost:1313/img/avatar.jpg" alt="Featured image of post AI与.NET技术实操系列（五）：向量存储与相似性搜索在 .NET 中的实现" /&gt;&lt;h2 id=&#34;引言&#34;&gt;引言
&lt;/h2&gt;&lt;p&gt;在当今这个数据爆炸的时代，信息的快速存储与高效检索已经成为技术领域的核心挑战。随着人工智能（AI）和机器学习（ML）的迅猛发展，向量存储和相似性搜索技术逐渐崭露头角，成为处理海量数据的利器。对于使用 .NET 的开发者来说，掌握这些技术不仅意味着能够开发出更智能、更高效的应用，更是在信息洪流中保持竞争力的关键。借助向量存储，我们可以将复杂的数据（如文本、图像或音频）转化为高维向量，通过相似性搜索快速找到与查询最相关的内容，从而大幅提升信息检索的精度和效率。&lt;/p&gt;
&lt;p&gt;向量存储和相似性搜索的应用潜力令人振奋。从智能推荐系统到图像检索工具，再到自然语言处理（NLP）中的语义搜索，这些技术正在重塑我们与数据的交互方式。通过在向量空间中使用距离度量（如余弦相似度或欧氏距离），开发者可以实现高效的匹配机制，为用户提供个性化的体验。然而，技术的实现并非一帆风顺，高维数据的存储、计算资源的优化、索引结构的构建以及实时性能的保障，都是开发者需要面对的难题。&lt;/p&gt;
&lt;p&gt;本文将通过一个具体的实践任务——实现一个简单的文档相似性搜索系统，深入探讨如何在 .NET 中应用向量存储和相似性搜索技术。我们将从基础知识入手，逐步介绍向量存储的选择与使用，并通过清晰的代码示例，引导读者完成一个功能完备的搜索应用。&lt;/p&gt;
&lt;p&gt;希望本文能为你打开向量存储的大门，激发你在 .NET 开发中探索智能技术的热情。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;向量存储和相似性搜索基础知识&#34;&gt;向量存储和相似性搜索基础知识
&lt;/h2&gt;&lt;p&gt;在进入实践之前，我们先来梳理向量存储和相似性搜索的基本概念及其工作原理。&lt;/p&gt;
&lt;h3 id=&#34;什么是向量存储&#34;&gt;什么是向量存储？
&lt;/h3&gt;&lt;p&gt;向量存储（Vector Store）是一种专门设计用于存储和检索高维向量的数据库系统。在 AI 和 ML 领域，数据通常被转化为高维向量（称为 embeddings），以捕捉其语义或特征信息。例如，一段文本可以通过预训练模型（如 BERT）转换为一个 384 维的向量，图像可以通过卷积神经网络提取特征向量。向量存储通过优化这些高维数据的存储结构和查询机制，支持快速的相似性搜索，帮助开发者高效地找到与查询最相关的内容。&lt;/p&gt;
&lt;h3 id=&#34;什么是相似性搜索&#34;&gt;什么是相似性搜索？
&lt;/h3&gt;&lt;p&gt;相似性搜索（Similarity Search）是一种旨在找到与查询项最相似的项的搜索技术。在向量空间中，相似性通常通过距离度量来衡量，常见的度量方法包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;余弦相似度&lt;/strong&gt;：计算两个向量夹角的余弦值，反映方向的相似性，广泛用于文本搜索。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;欧氏距离&lt;/strong&gt;：计算两个向量间的直线距离，常用于图像和数值数据的匹配。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;曼哈顿距离&lt;/strong&gt;：计算向量在各维度上的差值之和，适用于特定场景。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通过这些度量，相似性搜索能够在海量数据中快速定位与查询最接近的结果，极大地提升了搜索效率。&lt;/p&gt;
&lt;h3 id=&#34;向量存储的工作原理&#34;&gt;向量存储的工作原理
&lt;/h3&gt;&lt;p&gt;向量存储依赖以下核心技术来实现高效的存储和查询：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;索引结构&lt;/strong&gt;：如 KD-Tree、HNSW（层次可导航小世界图），用于加速相似性搜索。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;近似最近邻（ANN）&lt;/strong&gt;：通过牺牲少量精度换取更高的搜索速度，适用于大规模数据集。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分布式架构&lt;/strong&gt;：支持数据的并行处理和存储，满足高并发需求。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这些技术的结合使得向量存储能够应对高维数据的挑战，为实时应用提供强大支持。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;选择和使用向量存储&#34;&gt;选择和使用向量存储
&lt;/h2&gt;&lt;p&gt;在 .NET 中实现向量存储和相似性搜索，开发者可以选择多种工具和服务。以下是几个常见选项：&lt;/p&gt;
&lt;h3 id=&#34;milvus&#34;&gt;Milvus
&lt;/h3&gt;&lt;p&gt;Milvus 是一个开源的向量数据库，专为高维向量存储和搜索设计。它支持多种索引类型（如 HNSW、IVF）和距离度量，提供高性能的搜索能力。Milvus 可通过 RESTful API 或客户端 SDK 与 .NET 集成。&lt;/p&gt;
&lt;h3 id=&#34;qdrant&#34;&gt;qDrant
&lt;/h3&gt;&lt;p&gt;qDrant 是一个轻量级向量数据库，适合中小规模应用。它支持实时数据插入和搜索，提供简单易用的 API，方便快速上手。&lt;/p&gt;
&lt;h3 id=&#34;azure-ai-search&#34;&gt;Azure AI Search
&lt;/h3&gt;&lt;p&gt;Azure AI Search 是微软提供的云端搜索服务，支持向量搜索和全文搜索。它与 Azure 生态无缝集成，适合企业级应用。&lt;/p&gt;
&lt;p&gt;本文将以 Milvus 为例，展示如何在 .NET 中实现向量存储和搜索。Milvus 以其高性能和灵活性，成为许多 AI 项目的首选。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;实现文档相似性搜索系统&#34;&gt;实现文档相似性搜索系统
&lt;/h2&gt;&lt;p&gt;为了帮助读者深入理解向量存储的实际应用，我们将实现一个简单的文档相似性搜索系统。该系统能够将文档转换为向量，存储到 Milvus 中，并支持用户查询相似文档。&lt;/p&gt;
&lt;h3 id=&#34;系统设计&#34;&gt;系统设计
&lt;/h3&gt;&lt;p&gt;系统的核心组件包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;文档向量化&lt;/strong&gt;：使用预训练模型将文本转换为向量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;向量存储&lt;/strong&gt;：将向量存储到 Milvus 并构建索引。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;相似性搜索&lt;/strong&gt;：根据用户查询生成向量并搜索相似结果。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;结果展示&lt;/strong&gt;：返回最相似的文档。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们将使用 SentenceTransformers 生成向量，并通过 Milvus 实现存储和搜索。&lt;/p&gt;
&lt;h3 id=&#34;准备工作&#34;&gt;准备工作
&lt;/h3&gt;&lt;p&gt;在开始之前，需要完成以下准备：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;创建Milvus-Test&lt;/strong&gt;文件夹，并新建如下文件夹：
&lt;img src=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/0a29c1a7-b332-44d3-909b-9207c28eeb7e.png&#34;
	width=&#34;694&#34;
	height=&#34;198&#34;
	srcset=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/0a29c1a7-b332-44d3-909b-9207c28eeb7e_hu_70439e58b0ac0ea2.png 480w, http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/0a29c1a7-b332-44d3-909b-9207c28eeb7e_hu_aff1a7900db5799a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;350&#34;
		data-flex-basis=&#34;841px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;下载milvus-standalone-docker-compose.yml&lt;/strong&gt;，重命名成docker-compose.yml后移入到刚刚创建好的Milvus-Test文件夹中
&lt;img src=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/6fed7784-139e-4187-a6bb-d25277da5555.png&#34;
	width=&#34;933&#34;
	height=&#34;266&#34;
	srcset=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/6fed7784-139e-4187-a6bb-d25277da5555_hu_47dacfdad3396324.png 480w, http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/6fed7784-139e-4187-a6bb-d25277da5555_hu_4276cf8012a269a3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;350&#34;
		data-flex-basis=&#34;841px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;安装 Milvus&lt;/strong&gt;：使用 Docker 部署 Milvus（&lt;code&gt;docker compose up -d&lt;/code&gt;）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/4c5878ce-fa56-4a4d-a401-7c1ecbeb4ffa.png&#34;
	width=&#34;963&#34;
	height=&#34;504&#34;
	srcset=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/4c5878ce-fa56-4a4d-a401-7c1ecbeb4ffa_hu_fcc783d23af068af.png 480w, http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/4c5878ce-fa56-4a4d-a401-7c1ecbeb4ffa_hu_b13dec5954e6e18b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;191&#34;
		data-flex-basis=&#34;458px&#34;
	
&gt;
&lt;img src=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/64302f98-706b-4923-bbcd-3a11587be208.png&#34;
	width=&#34;1208&#34;
	height=&#34;214&#34;
	srcset=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/64302f98-706b-4923-bbcd-3a11587be208_hu_4242f741ff52366e.png 480w, http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/64302f98-706b-4923-bbcd-3a11587be208_hu_b3198bc715407109.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;564&#34;
		data-flex-basis=&#34;1354px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;实现步骤&#34;&gt;实现步骤
&lt;/h3&gt;&lt;h4 id=&#34;1-文档向量化&#34;&gt;1. 文档向量化
&lt;/h4&gt;&lt;p&gt;首先，使用 SentenceTransformers 将文档转换为向量（需 Python 环境）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;from sentence_transformers import SentenceTransformermodel = SentenceTransformer(&amp;#39;all-MiniLM-L6-v2&amp;#39;)documents = [&amp;#34;This is document one.&amp;#34;, &amp;#34;This is document two.&amp;#34;, &amp;#34;This is document three.&amp;#34;]embeddings = model.encode(documents)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;code&gt;embeddings&lt;/code&gt; 是包含每个文档向量的数组（维度为 384）。&lt;/p&gt;
&lt;h4 id=&#34;2-存储向量到-milvus&#34;&gt;2. 存储向量到 Milvus
&lt;/h4&gt;&lt;p&gt;安装Nuget包：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;dotnet add package Milvus.Client --version 2.3.0-preview.1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;使用 C# 检测 Milvus 是否正常运行的代码：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;MilvusClient milvusClient = new MilvusClient(&amp;#34;{Endpoint}&amp;#34;, &amp;#34;{Port}&amp;#34;, &amp;#34;{Username}&amp;#34;, &amp;#34;{Password}&amp;#34;, &amp;#34;{Database}(Optional)&amp;#34;);MilvusHealthState result = await milvusClient.HealthAsync();
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/d3591700-6afb-4de9-9fca-a44905ba27cc.png&#34;
	width=&#34;680&#34;
	height=&#34;126&#34;
	srcset=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/d3591700-6afb-4de9-9fca-a44905ba27cc_hu_59ff9dd6446ad3a3.png 480w, http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/d3591700-6afb-4de9-9fca-a44905ba27cc_hu_149f4bb66a86f5a0.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;539&#34;
		data-flex-basis=&#34;1295px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;使用 C# 调用 Milvus 创建集合代码：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-gdscript3&#34; data-lang=&#34;gdscript3&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;collectionName&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;book&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MilvusCollection&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;collection&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;milvusClient&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GetCollection&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;collectionName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;//&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Check&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;this&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;collection&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;existsvar&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;hasCollection&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;await&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;milvusClient&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;HasCollectionAsync&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;collectionName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;hasCollection&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;await&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;collection&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;DropAsync&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;Console&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;WriteLine&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Drop collection {0}&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;collectionName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);}&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;await&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;milvusClient&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CreateCollectionAsync&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;            &lt;span class=&#34;n&#34;&gt;collectionName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;            &lt;span class=&#34;n&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;                &lt;span class=&#34;n&#34;&gt;FieldSchema&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Create&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;long&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;book_id&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;isPrimaryKey&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;                &lt;span class=&#34;n&#34;&gt;FieldSchema&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Create&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;long&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;word_count&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;                &lt;span class=&#34;n&#34;&gt;FieldSchema&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CreateVarchar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;book_name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;256&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;                &lt;span class=&#34;n&#34;&gt;FieldSchema&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CreateFloatVector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;book_intro&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;L&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;            &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;        &lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;使用 C# 调用 Milvus 插入向量代码：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Random ran = new ();List&amp;lt;long&amp;gt; bookIds = new ();List&amp;lt;long&amp;gt; wordCounts = new ();List&amp;lt;ReadOnlyMemory&amp;lt;float&amp;gt;&amp;gt; bookIntros = new ();List&amp;lt;string&amp;gt; bookNames = new ();for (long i = 0L; i &amp;lt; 2000; ++i){    bookIds.Add(i);    wordCounts.Add(i + 10000);    bookNames.Add($&amp;#34;Book Name {i}&amp;#34;);    float[] vector = new float[2];    for (int k = 0; k &amp;lt; 2; ++k)    {        vector[k] = ran.Next();    }    bookIntros.Add(vector);}MilvusCollection collection = milvusClient.GetCollection(collectionName);MutationResult result = await collection.InsertAsync(    new FieldData[]    {        FieldData.Create(&amp;#34;book_id&amp;#34;, bookIds),        FieldData.Create(&amp;#34;word_count&amp;#34;, wordCounts),        FieldData.Create(&amp;#34;book_name&amp;#34;, bookNames),        FieldData.CreateFloatVector(&amp;#34;book_intro&amp;#34;, bookIntros),    });// Check resultConsole.WriteLine(&amp;#34;Insert count:{0},&amp;#34;, result.InsertCount);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/d4dbabbb-9320-455a-8b76-360979bc8013.png&#34;
	width=&#34;982&#34;
	height=&#34;495&#34;
	srcset=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/d4dbabbb-9320-455a-8b76-360979bc8013_hu_4eb44ddb22198ffd.png 480w, http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/d4dbabbb-9320-455a-8b76-360979bc8013_hu_cd7275f9ed78586f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;198&#34;
		data-flex-basis=&#34;476px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;3-构建索引&#34;&gt;3. 构建索引
&lt;/h4&gt;&lt;p&gt;为加速搜索，需在集合上构建索引：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-gdscript3&#34; data-lang=&#34;gdscript3&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;MilvusCollection&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;collection&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;milvusClient&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GetCollection&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;collectionName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;await&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;collection&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CreateIndexAsync&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;    &lt;span class=&#34;s2&#34;&gt;&amp;#34;book_intro&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;//&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MilvusIndexType&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;IVF_FLAT&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;//&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Use&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;MilvusIndexType&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;IVF_FLAT&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;IndexType&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;AutoIndex&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;//&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Use&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;MilvusIndexType&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;AUTOINDEX&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;when&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;you&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;are&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;using&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;zilliz&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cloud&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;SimilarityMetricType&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;L2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;//&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Check&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;index&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;statusIList&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MilvusIndexInfo&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;indexInfos&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;await&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;collection&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;DescribeIndexAsync&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;book_intro&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;foreach&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;info&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;indexInfos&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;Console&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;WriteLine&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;FieldName:{0}, IndexName:{1}, IndexId:{2}&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;info&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;FieldName&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;info&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;IndexName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;info&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;IndexId&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);}&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;//&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Then&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;load&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;itawait&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;collection&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;LoadAsync&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/ea0a9df9-c122-4fa7-be6a-52d7c4c97c39.png&#34;
	width=&#34;1185&#34;
	height=&#34;307&#34;
	srcset=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/ea0a9df9-c122-4fa7-be6a-52d7c4c97c39_hu_2d592be7877451c0.png 480w, http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/ea0a9df9-c122-4fa7-be6a-52d7c4c97c39_hu_d7b439daafa126ae.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;385&#34;
		data-flex-basis=&#34;926px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;4-实现相似性搜索&#34;&gt;4. 实现相似性搜索
&lt;/h4&gt;&lt;p&gt;根据用户查询搜索相似文档：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;List&amp;lt;string&amp;gt; search_output_fields = new() { &amp;#34;book_id&amp;#34; };List&amp;lt;List&amp;lt;float&amp;gt;&amp;gt; search_vectors = new() { new() { 0.1f, 0.2f } };SearchResults searchResult = await collection.SearchAsync(    &amp;#34;book_intro&amp;#34;,    new ReadOnlyMemory&amp;lt;float&amp;gt;[] { new[] { 0.1f, 0.2f } },    SimilarityMetricType.L2,    limit: 2);// Querystring expr = &amp;#34;book_id in [2,4,6,8]&amp;#34;;QueryParameters queryParameters = new ();queryParameters.OutputFields.Add(&amp;#34;book_id&amp;#34;);queryParameters.OutputFields.Add(&amp;#34;word_count&amp;#34;);IReadOnlyList&amp;lt;FieldData&amp;gt; queryResult = await collection.QueryAsync(    expr,    queryParameters);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/20695ad0-3c23-4fe0-a86f-1303db89f9ea.png&#34;
	width=&#34;849&#34;
	height=&#34;208&#34;
	srcset=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/20695ad0-3c23-4fe0-a86f-1303db89f9ea_hu_5bbef586a629ef27.png 480w, http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/20695ad0-3c23-4fe0-a86f-1303db89f9ea_hu_c7abd7970d3f7854.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;408&#34;
		data-flex-basis=&#34;979px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;5-集成到应用&#34;&gt;5. 集成到应用
&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;❝&lt;/p&gt;
&lt;p&gt;后面要做的事情就很多了，大家可以自行发挥，当然有兴趣的朋友还可以安装attu ui界面作为
Milvus的客户端，小编并没有安装，因此我截取官方图片让大家看一下，地址为：https://github.com/zilliztech/attu/releases。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/0392389c-5d48-4095-aacd-7394ae729388.png&#34;
	width=&#34;2191&#34;
	height=&#34;981&#34;
	srcset=&#34;http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/0392389c-5d48-4095-aacd-7394ae729388_hu_6caa11c2b4987018.png 480w, http://localhost:1313/post/ai%E4%B8%8E.net%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%93%8D%E7%B3%BB%E5%88%97%E4%BA%94%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2%E5%9C%A8-.net-%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0/images/0392389c-5d48-4095-aacd-7394ae729388_hu_449b9590477ac139.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;223&#34;
		data-flex-basis=&#34;536px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;实际应用中的意义与挑战&#34;&gt;实际应用中的意义与挑战
&lt;/h2&gt;&lt;h3 id=&#34;意义&#34;&gt;意义
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;提升用户体验&lt;/strong&gt;：语义搜索提供更精准的结果。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多模态支持&lt;/strong&gt;：可扩展到图像、音频等领域。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;效率优化&lt;/strong&gt;：加速信息检索和决策。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;挑战&#34;&gt;挑战
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;资源需求&lt;/strong&gt;：高维数据需要大量计算和存储资源。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;索引优化&lt;/strong&gt;：需平衡速度与精度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;实时性&lt;/strong&gt;：高并发场景下的性能保障。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;结语&#34;&gt;结语
&lt;/h2&gt;&lt;p&gt;本文通过理论与实践结合，展示了在 .NET 中实现向量存储和相似性搜索的方法。希望你能从中获得启发，在智能应用的浪潮中找到自己的位置。向量存储的潜力无限，让我们共同探索这一领域，在技术的海洋里尽情驰骋！&lt;/p&gt;
&lt;p&gt;参考链接:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.nuget.org/packages/Milvus.Client/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.nuget.org/packages/Milvus.Client/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/zilliztech/attu/blob/main/.github/images/collection&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/zilliztech/attu/blob/main/.github/images/collection&lt;/a&gt;_overview.png&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>投屏协议 Miracast、AirPlay、DLNA、Chromecast以及WiDi五大投屏协议详细介绍</title>
        <link>http://localhost:1313/post/%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE-miracastairplaydlnachromecast%E4%BB%A5%E5%8F%8Awidi%E4%BA%94%E5%A4%A7%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/</link>
        <pubDate>Fri, 14 Mar 2025 23:16:45 +0800</pubDate>
        
        <guid>http://localhost:1313/post/%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE-miracastairplaydlnachromecast%E4%BB%A5%E5%8F%8Awidi%E4%BA%94%E5%A4%A7%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/</guid>
        <description>&lt;img src="http://localhost:1313/post/%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE-miracastairplaydlnachromecast%E4%BB%A5%E5%8F%8Awidi%E4%BA%94%E5%A4%A7%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/images/LDQ1bOKTfoNTycxnhgscFidkn1b.png" alt="Featured image of post 投屏协议 Miracast、AirPlay、DLNA、Chromecast以及WiDi五大投屏协议详细介绍" /&gt;&lt;p&gt;&lt;strong&gt;无线投屏协议&lt;/strong&gt;是指通过无线网络将智能移动设备的屏幕图像和声音实时传输至另一台显示设备上，实现内容的同屏展示的技术标准。目前，市场上存在多种无线投屏协议，其中五大主流的无线投屏协议包括&lt;strong&gt;Miracast、AirPlay、DLNA、Chromecast以及WiDi&lt;/strong&gt;。以下是对这五大协议的详细介绍：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/post/%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE-miracastairplaydlnachromecast%E4%BB%A5%E5%8F%8Awidi%E4%BA%94%E5%A4%A7%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/images/LDQ1bOKTfoNTycxnhgscFidkn1b.png&#34;
	width=&#34;651&#34;
	height=&#34;505&#34;
	srcset=&#34;http://localhost:1313/post/%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE-miracastairplaydlnachromecast%E4%BB%A5%E5%8F%8Awidi%E4%BA%94%E5%A4%A7%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/images/LDQ1bOKTfoNTycxnhgscFidkn1b_hu_4f4e0bb86ea7c5d7.png 480w, http://localhost:1313/post/%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE-miracastairplaydlnachromecast%E4%BB%A5%E5%8F%8Awidi%E4%BA%94%E5%A4%A7%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/images/LDQ1bOKTfoNTycxnhgscFidkn1b_hu_883d300b451868f9.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;128&#34;
		data-flex-basis=&#34;309px&#34;
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;1-miracast&#34;&gt;1. Miracast
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;技术特点&lt;/strong&gt;：由Wi-Fi联盟制定，以WIFI连接为基础的&lt;strong&gt;无线投屏&lt;/strong&gt;协议，支持Android和Windows设备。&lt;strong&gt;Miracast无线投屏&lt;/strong&gt;是兼容性最广的投屏协议，国内大多数Android手机、智能电视都支持&lt;strong&gt;Miracast投屏协议&lt;/strong&gt;。&lt;strong&gt;Miracast&lt;/strong&gt;使用Wi-Fi Direct技术，设备之间直接建立连接，无需依赖路由器或互联网&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;适用设备&lt;/strong&gt;：Android 5.0以上手机、Windows 8/10电脑。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;限制&lt;/strong&gt;：传输基于UDP协议，易受干扰，可能导致接收端画质问题；不同Android设备开启&lt;strong&gt;Miracast&lt;/strong&gt;的方式不一致，推广困难。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/post/%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE-miracastairplaydlnachromecast%E4%BB%A5%E5%8F%8Awidi%E4%BA%94%E5%A4%A7%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/images/O3QXbIMWHo7b1bx3SJ8camkQn0c.png&#34;
	width=&#34;1064&#34;
	height=&#34;650&#34;
	srcset=&#34;http://localhost:1313/post/%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE-miracastairplaydlnachromecast%E4%BB%A5%E5%8F%8Awidi%E4%BA%94%E5%A4%A7%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/images/O3QXbIMWHo7b1bx3SJ8camkQn0c_hu_bfd8a606ebf5363b.png 480w, http://localhost:1313/post/%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE-miracastairplaydlnachromecast%E4%BB%A5%E5%8F%8Awidi%E4%BA%94%E5%A4%A7%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/images/O3QXbIMWHo7b1bx3SJ8camkQn0c_hu_be2d1d81fe55dd37.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;163&#34;
		data-flex-basis=&#34;392px&#34;
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;2-airplay&#34;&gt;2. AirPlay
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;技术特点&lt;/strong&gt;：苹果开发的一种无线技术，通过Wi-Fi将iPhone、iPad等iOS设备上的音视频、图片通过无线方式传输到支持&lt;strong&gt;AirPlay&lt;/strong&gt;的设备，如Apple TV、智能电视等。&lt;strong&gt;AirPlay&lt;/strong&gt;支持推送和镜像两种模式，具有高清、低延迟、易用等特点。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;操作方式&lt;/strong&gt;：在iOS设备上呼出控制中心，选择“&lt;strong&gt;屏幕镜像&lt;/strong&gt;”并连接目标设备。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;限制&lt;/strong&gt;：要求苹果设备与投屏设备在同一局域网内，不支持跨网段使用。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;3-dlna&#34;&gt;3. DLNA
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;技术特点&lt;/strong&gt;：由索尼、英特尔、微软等发起的一套PC、移动设备、消费电器之间互联互通的协议。&lt;strong&gt;DLNA&lt;/strong&gt;只支持推送模式，具有标准化、跨平台、易扩展等特点。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;适用场景&lt;/strong&gt;：家庭影院，不太适合企业环境。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;优势&lt;/strong&gt;：画质无损，对网络要求较高。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;4-chromecast&#34;&gt;4. Chromecast
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;技术特点&lt;/strong&gt;：谷歌开发的&lt;strong&gt;无线投屏技术&lt;/strong&gt;，需要使用一个小型的硬件设备插入电视或显示器的HDMI接口，然后通过WiFi与手机或电脑连接，实现视频、音乐、网页等内容的&lt;strong&gt;投屏&lt;/strong&gt;。&lt;strong&gt;Chromecast&lt;/strong&gt;支持推送和镜像两种模式，具有智能化、云端化、开放性等特点。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;优势&lt;/strong&gt;：体验更接近于DLNA，但比DLNA更加灵活和智能。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;5-widi&#34;&gt;5. WiDi
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;技术特点&lt;/strong&gt;：全称为Intel Wireless Display（无线高清技术），是Intel公司开发的一种&lt;strong&gt;无线投屏技术&lt;/strong&gt;。它允许用户通过WiFi信号将电脑屏幕的内容无线传输到支持WiDi的显示设备上。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;优势&lt;/strong&gt;：无需安装软件，即可实现&lt;strong&gt;无线投屏&lt;/strong&gt;，使用便捷。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;限制&lt;/strong&gt;：需要发射端设备具备HDMI输出接口，限制了使用范围。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/post/%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE-miracastairplaydlnachromecast%E4%BB%A5%E5%8F%8Awidi%E4%BA%94%E5%A4%A7%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/images/INV9bUKusoj1NvxpYMecdAdenJq.png&#34;
	width=&#34;872&#34;
	height=&#34;564&#34;
	srcset=&#34;http://localhost:1313/post/%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE-miracastairplaydlnachromecast%E4%BB%A5%E5%8F%8Awidi%E4%BA%94%E5%A4%A7%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/images/INV9bUKusoj1NvxpYMecdAdenJq_hu_187cb1b2ae1c43ca.png 480w, http://localhost:1313/post/%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE-miracastairplaydlnachromecast%E4%BB%A5%E5%8F%8Awidi%E4%BA%94%E5%A4%A7%E6%8A%95%E5%B1%8F%E5%8D%8F%E8%AE%AE%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/images/INV9bUKusoj1NvxpYMecdAdenJq_hu_4613e509a5eb447b.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;154&#34;
		data-flex-basis=&#34;371px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;综上所述，这&lt;strong&gt;五大无线投屏协议&lt;/strong&gt;各有其技术特点和适用场景。在选择&lt;strong&gt;投屏协议&lt;/strong&gt;时，用户应根据自身设备、网络环境以及使用需求来做出合理的选择。&lt;/p&gt;
&lt;p&gt;参考链接：&lt;/p&gt;
</description>
        </item>
        <item>
        <title>0314 这是的啊的啊</title>
        <link>http://localhost:1313/post/0314-%E8%BF%99%E6%98%AF%E7%9A%84%E5%95%8A%E7%9A%84%E5%95%8A/</link>
        <pubDate>Fri, 14 Mar 2025 22:57:04 +0800</pubDate>
        
        <guid>http://localhost:1313/post/0314-%E8%BF%99%E6%98%AF%E7%9A%84%E5%95%8A%E7%9A%84%E5%95%8A/</guid>
        <description>&lt;img src="http://localhost:1313/img/avatar.jpg" alt="Featured image of post 0314 这是的啊的啊" /&gt;&lt;!--正文内容--&gt;</description>
        </item>
        <item>
        <title>0314 创建新的文章22</title>
        <link>http://localhost:1313/post/chinese-testa/</link>
        <pubDate>Fri, 14 Mar 2025 22:46:28 +0800</pubDate>
        
        <guid>http://localhost:1313/post/chinese-testa/</guid>
        <description>&lt;img src="http://localhost:1313/img/avatar.jpg" alt="Featured image of post 0314 创建新的文章22" /&gt;&lt;h2 id=&#34;正文测试&#34;&gt;正文测试
&lt;/h2&gt;&lt;p&gt;。&lt;/p&gt;
&lt;p&gt;奥斯特洛夫斯基曾经说过，共同的事业，共同的斗争，可以使人们产生忍受一切的力量。　带着这句话，我们还要更加慎重的审视这个问题： 一般来讲，我们都必须务必慎重的考虑考虑。 既然如此， 这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 带着这些问题，我们来审视一下学生会退会。 我认为， 我认为， 在这种困难的抉择下，本人思来想去，寝食难安。 问题的关键究竟为何？ 每个人都不得不面对这些问题。 在面对这种问题时， 要想清楚，学生会退会，到底是一种怎么样的存在。 我认为， 既然如此， 每个人都不得不面对这些问题。 在面对这种问题时， 那么， 我认为， 学生会退会因何而发生。&lt;/p&gt;
&lt;h2 id=&#34;引用&#34;&gt;引用
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;思念是最暖的忧伤像一双翅膀&lt;br&gt;
让我停不了飞不远在过往游荡&lt;br&gt;
不告而别的你 就算为了我着想&lt;br&gt;
这么沉痛的呵护 我怎么能翱翔&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=3aypp_YlBzI&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;最暖的憂傷 - 田馥甄&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;图片&#34;&gt;图片
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/post/chinese-testa/florian-klauer-nptLmg6jqDo-unsplash.jpg&#34;
	width=&#34;667&#34;
	height=&#34;1000&#34;
	srcset=&#34;http://localhost:1313/post/chinese-testa/florian-klauer-nptLmg6jqDo-unsplash_hu_e98fca2b4272416e.jpg 480w, http://localhost:1313/post/chinese-testa/florian-klauer-nptLmg6jqDo-unsplash_hu_e3d37c9ded115b12.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Photo by Florian Klauer on Unsplash&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;66&#34;
		data-flex-basis=&#34;160px&#34;
	
&gt;  &lt;img src=&#34;http://localhost:1313/post/chinese-testa/luca-bravo-alS7ewQ41M8-unsplash.jpg&#34;
	width=&#34;1000&#34;
	height=&#34;667&#34;
	srcset=&#34;http://localhost:1313/post/chinese-testa/luca-bravo-alS7ewQ41M8-unsplash_hu_e13c58d5189f892c.jpg 480w, http://localhost:1313/post/chinese-testa/luca-bravo-alS7ewQ41M8-unsplash_hu_8fc948b7ee525251.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Photo by Luca Bravo on Unsplash&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;149&#34;
		data-flex-basis=&#34;359px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/post/chinese-testa/helena-hertz-wWZzXlDpMog-unsplash.jpg&#34;
	width=&#34;1000&#34;
	height=&#34;750&#34;
	srcset=&#34;http://localhost:1313/post/chinese-testa/helena-hertz-wWZzXlDpMog-unsplash_hu_503c0ebcc5245e10.jpg 480w, http://localhost:1313/post/chinese-testa/helena-hertz-wWZzXlDpMog-unsplash_hu_48c98de55fb3c999.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Photo by Helena Hertz on Unsplash&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;  &lt;img src=&#34;http://localhost:1313/post/chinese-testa/hudai-gayiran-3Od_VKcDEAA-unsplash.jpg&#34;
	width=&#34;667&#34;
	height=&#34;1000&#34;
	srcset=&#34;http://localhost:1313/post/chinese-testa/hudai-gayiran-3Od_VKcDEAA-unsplash_hu_f81a3588c5c4a663.jpg 480w, http://localhost:1313/post/chinese-testa/hudai-gayiran-3Od_VKcDEAA-unsplash_hu_1c52ba2a4ad7b9a0.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Photo by Hudai Gayiran on Unsplash&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;66&#34;
		data-flex-basis=&#34;160px&#34;
	
&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;![&lt;span class=&#34;nt&#34;&gt;Photo by Florian Klauer on Unsplash&lt;/span&gt;](&lt;span class=&#34;na&#34;&gt;florian-klauer-nptLmg6jqDo-unsplash.jpg&lt;/span&gt;)  ![&lt;span class=&#34;nt&#34;&gt;Photo by Luca Bravo on Unsplash&lt;/span&gt;](&lt;span class=&#34;na&#34;&gt;luca-bravo-alS7ewQ41M8-unsplash.jpg&lt;/span&gt;) 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;![&lt;span class=&#34;nt&#34;&gt;Photo by Helena Hertz on Unsplash&lt;/span&gt;](&lt;span class=&#34;na&#34;&gt;helena-hertz-wWZzXlDpMog-unsplash.jpg&lt;/span&gt;)  ![&lt;span class=&#34;nt&#34;&gt;Photo by Hudai Gayiran on Unsplash&lt;/span&gt;](&lt;span class=&#34;na&#34;&gt;hudai-gayiran-3Od_VKcDEAA-unsplash.jpg&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;相册语法来自 &lt;a class=&#34;link&#34; href=&#34;https://typlog.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Typlog&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>0314 创建新的文章</title>
        <link>http://localhost:1313/post/0314-%E5%88%9B%E5%BB%BA%E6%96%B0%E7%9A%84%E6%96%87%E7%AB%A0/</link>
        <pubDate>Fri, 14 Mar 2025 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/post/0314-%E5%88%9B%E5%BB%BA%E6%96%B0%E7%9A%84%E6%96%87%E7%AB%A0/</guid>
        <description>&lt;img src="http://localhost:1313/img/avatar.jpg" alt="Featured image of post 0314 创建新的文章" /&gt;&lt;!--正文内容--&gt;
&lt;p&gt;aaaaaa&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>
